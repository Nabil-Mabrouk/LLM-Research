## Do Multilingual Language Models Capture Differing Moral Norms?

**Published Date:** 2022-03-18T12:26:37Z

**Link:** http://arxiv.org/pdf/2203.09904v1

**Abstract:**

  Massively multilingual sentence representations are trained on large corpora
of uncurated data, with a very imbalanced proportion of languages included in
the training. This may cause the models to grasp cultural values including
moral judgments from the high-resource languages and impose them on the
low-resource languages. The lack of data in certain languages can also lead to
developing random and thus potentially harmful beliefs. Both these issues can
negatively influence zero-shot cross-lingual model transfer and potentially
lead to harmful outcomes. Therefore, we aim to (1) detect and quantify these
issues by comparing different models in different languages, (2) develop
methods for improving undesirable properties of the models. Our initial
experiments using the multilingual model XLM-R show that indeed multilingual
LMs capture moral norms, even with potentially higher human-agreement than
monolingual ones. However, it is not yet clear to what extent these moral norms
differ between languages.


---

## Do Multilingual Language Models Capture Differing Moral Norms?

**Published Date:** 2022-03-18T12:26:37Z

**Link:** http://arxiv.org/pdf/2203.09904v1

**Abstract:**

  Massively multilingual sentence representations are trained on large corpora
of uncurated data, with a very imbalanced proportion of languages included in
the training. This may cause the models to grasp cultural values including
moral judgments from the high-resource languages and impose them on the
low-resource languages. The lack of data in certain languages can also lead to
developing random and thus potentially harmful beliefs. Both these issues can
negatively influence zero-shot cross-lingual model transfer and potentially
lead to harmful outcomes. Therefore, we aim to (1) detect and quantify these
issues by comparing different models in different languages, (2) develop
methods for improving undesirable properties of the models. Our initial
experiments using the multilingual model XLM-R show that indeed multilingual
LMs capture moral norms, even with potentially higher human-agreement than
monolingual ones. However, it is not yet clear to what extent these moral norms
differ between languages.


---

## Graph Neural Network Enhanced Language Models for Efficient Multilingual
  Text Classification

**Published Date:** 2022-03-06T09:05:42Z

**Link:** http://arxiv.org/pdf/2203.02912v1

**Abstract:**

  Online social media works as a source of various valuable and actionable
information during disasters. These information might be available in multiple
languages due to the nature of user generated content. An effective system to
automatically identify and categorize these actionable information should be
capable to handle multiple languages and under limited supervision. However,
existing works mostly focus on English language only with the assumption that
sufficient labeled data is available. To overcome these challenges, we propose
a multilingual disaster related text classification system which is capable to
work under \{mono, cross and multi\} lingual scenarios and under limited
supervision. Our end-to-end trainable framework combines the versatility of
graph neural networks, by applying over the corpus, with the power of
transformer based large language models, over examples, with the help of
cross-attention between the two. We evaluate our framework over total nine
English, Non-English and monolingual datasets in \{mono, cross and multi\}
lingual classification scenarios. Our framework outperforms state-of-the-art
models in disaster domain and multilingual BERT baseline in terms of Weighted
F$_1$ score. We also show the generalizability of the proposed model under
limited supervision.


---

## Do Multilingual Language Models Capture Differing Moral Norms?

**first_author:** Katharina Hämmerl et al.

**Published Date:** 2022-03-18T12:26:37Z

**Link:** http://arxiv.org/pdf/2203.09904v1

**Abstract:**

  Massively multilingual sentence representations are trained on large corpora
of uncurated data, with a very imbalanced proportion of languages included in
the training. This may cause the models to grasp cultural values including
moral judgments from the high-resource languages and impose them on the
low-resource languages. The lack of data in certain languages can also lead to
developing random and thus potentially harmful beliefs. Both these issues can
negatively influence zero-shot cross-lingual model transfer and potentially
lead to harmful outcomes. Therefore, we aim to (1) detect and quantify these
issues by comparing different models in different languages, (2) develop
methods for improving undesirable properties of the models. Our initial
experiments using the multilingual model XLM-R show that indeed multilingual
LMs capture moral norms, even with potentially higher human-agreement than
monolingual ones. However, it is not yet clear to what extent these moral norms
differ between languages.


---

