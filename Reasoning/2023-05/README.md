## Enhance Reasoning Ability of Visual-Language Models via Large Language
  Models

**Published Date:** 2023-05-22T17:33:44Z

**Link:** http://arxiv.org/pdf/2305.13267v1

**Abstract:**

  Pre-trained visual language models (VLM) have shown excellent performance in
image caption tasks. However, it sometimes shows insufficient reasoning
ability. In contrast, large language models (LLMs) emerge with powerful
reasoning capabilities. Therefore, we propose a method called TReE, which
transfers the reasoning ability of a large language model to a visual language
model in zero-shot scenarios. TReE contains three stages: observation,
thinking, and re-thinking. Observation stage indicates that VLM obtains the
overall information of the relative image. Thinking stage combines the image
information and task description as the prompt of the LLM, inference with the
rationals. Re-Thinking stage learns from rationale and then inference the final
result through VLM.


---

## Re-visiting Automated Topic Model Evaluation with Large Language Models

**Published Date:** 2023-05-20T09:42:00Z

**Link:** http://arxiv.org/pdf/2305.12152v1

**Abstract:**

  Topic models are used to make sense of large text collections. However,
automatically evaluating topic model output and determining the optimal number
of topics both have been longstanding challenges, with no effective automated
solutions to date. This paper proposes using large language models to evaluate
such output. We find that large language models appropriately assess the
resulting topics, correlating more strongly with human judgments than existing
automated metrics. We then investigate whether we can use large language models
to automatically determine the optimal number of topics. We automatically
assign labels to documents and choosing configurations with the most pure
labels returns reasonable values for the optimal number of topics.


---

## LANCE: Stress-testing Visual Models by Generating Language-guided
  Counterfactual Images

**Published Date:** 2023-05-30T16:09:16Z

**Link:** http://arxiv.org/pdf/2305.19164v1

**Abstract:**

  We propose an automated algorithm to stress-test a trained visual model by
generating language-guided counterfactual test images (LANCE). Our method
leverages recent progress in large language modeling and text-based image
editing to augment an IID test set with a suite of diverse, realistic, and
challenging test images without altering model weights. We benchmark the
performance of a diverse set of pretrained models on our generated data and
observe significant and consistent performance drops. We further analyze model
sensitivity across different types of edits, and demonstrate its applicability
at surfacing previously unknown class-level model biases in ImageNet.


---

## Language Models Can Improve Event Prediction by Few-Shot Abductive
  Reasoning

**Published Date:** 2023-05-26T05:32:29Z

**Link:** http://arxiv.org/pdf/2305.16646v1

**Abstract:**

  Large language models have shown astonishing performance on a wide range of
reasoning tasks. In this paper, we investigate whether they could reason about
real-world events and help improve the prediction accuracy of event sequence
models. We design a modeling and prediction framework where a large language
model performs abductive reasoning to assist an event sequence model: the event
model proposes predictions on future events given the past; instructed by a few
expert-annotated demonstrations, the language model learns to suggest possible
causes for each proposal; a search module finds out the previous events that
match the causes; a scoring function learns to examine whether the retrieved
events could actually cause the proposal. Through extensive experiments on two
challenging real-world datasets (Amazon Review and GDELT), we demonstrate that
our framework -- thanks to the reasoning ability of language models -- could
significantly outperform the state-of-the-art event sequence models.


---

## Enhance Reasoning Ability of Visual-Language Models via Large Language
  Models

**Published Date:** 2023-05-22T17:33:44Z

**Link:** http://arxiv.org/pdf/2305.13267v1

**Abstract:**

  Pre-trained visual language models (VLM) have shown excellent performance in
image caption tasks. However, it sometimes shows insufficient reasoning
ability. In contrast, large language models (LLMs) emerge with powerful
reasoning capabilities. Therefore, we propose a method called TReE, which
transfers the reasoning ability of a large language model to a visual language
model in zero-shot scenarios. TReE contains three stages: observation,
thinking, and re-thinking. Observation stage indicates that VLM obtains the
overall information of the relative image. Thinking stage combines the image
information and task description as the prompt of the LLM, inference with the
rationals. Re-Thinking stage learns from rationale and then inference the final
result through VLM.


---

## Chain-of-Thought Hub: A Continuous Effort to Measure Large Language
  Models' Reasoning Performance

**Published Date:** 2023-05-26T23:46:42Z

**Link:** http://arxiv.org/pdf/2305.17306v1

**Abstract:**

  As large language models (LLMs) are continuously being developed, their
evaluation becomes increasingly important yet challenging. This work proposes
Chain-of-Thought Hub, an open-source evaluation suite on the multi-step
reasoning capabilities of large language models. We are interested in this
setting for two reasons: (1) from the behavior of GPT and PaLM model family, we
observe that complex reasoning is likely to be a key differentiator between
weaker and stronger LLMs; (2) we envisage large language models to become the
next-generation computational platform and foster an ecosystem of LLM-based new
applications, this naturally requires the foundation models to perform complex
tasks that often involve the composition of linguistic and logical operations.
Our approach is to compile a suite of challenging reasoning benchmarks to track
the progress of LLMs. Our current results show that: (1) model scale clearly
correlates with reasoning capabilities; (2) As of May 2023, Claude-v1.3 and
PaLM-2 are the only two models that are comparable with GPT-4, while
open-sourced models still lag behind; (3) LLaMA-65B performs closely to
code-davinci-002, indicating that with successful further development such as
reinforcement learning from human feedback (RLHF), it has great potential to be
close to GPT-3.5-Turbo. Our results also suggest that for the open-source
efforts to catch up, the community may focus more on building better base
models and exploring RLHF.


---

## Enhance Reasoning Ability of Visual-Language Models via Large Language
  Models

**first_author:** Yueting Yang et al.

**Published Date:** 2023-05-22T17:33:44Z

**Link:** http://arxiv.org/pdf/2305.13267v1

**Abstract:**

  Pre-trained visual language models (VLM) have shown excellent performance in
image caption tasks. However, it sometimes shows insufficient reasoning
ability. In contrast, large language models (LLMs) emerge with powerful
reasoning capabilities. Therefore, we propose a method called TReE, which
transfers the reasoning ability of a large language model to a visual language
model in zero-shot scenarios. TReE contains three stages: observation,
thinking, and re-thinking. Observation stage indicates that VLM obtains the
overall information of the relative image. Thinking stage combines the image
information and task description as the prompt of the LLM, inference with the
rationals. Re-Thinking stage learns from rationale and then inference the final
result through VLM.


---

