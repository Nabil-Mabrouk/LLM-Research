## Do Large Language Models know what humans know?

**Published Date:** 2022-09-04T01:29:53Z

**Link:** http://arxiv.org/pdf/2209.01515v3

**Abstract:**

  Humans can attribute beliefs to others. However, it is unknown to what extent
this ability results from an innate biological endowment or from experience
accrued through child development, particularly exposure to language describing
others' mental states. We test the viability of the language exposure
hypothesis by assessing whether models exposed to large quantities of human
language display sensitivity to the implied knowledge states of characters in
written passages. In pre-registered analyses, we present a linguistic version
of the False Belief Task to both human participants and a Large Language Model,
GPT-3. Both are sensitive to others' beliefs, but while the language model
significantly exceeds chance behavior, it does not perform as well as the
humans, nor does it explain the full extent of their behavior -- despite being
exposed to more language than a human would in a lifetime. This suggests that
while statistical learning from language exposure may in part explain how
humans develop the ability to reason about the mental states of others, other
mechanisms are also responsible.


---

## Psychologically-informed chain-of-thought prompts for metaphor
  understanding in large language models

**Published Date:** 2022-09-16T19:23:13Z

**Link:** http://arxiv.org/pdf/2209.08141v2

**Abstract:**

  Probabilistic models of language understanding are valuable tools for
investigating human language use. However, they need to be hand-designed for a
particular domain. In contrast, large language models (LLMs) are trained on
text that spans a wide array of domains, but they lack the structure and
interpretability of probabilistic models. In this paper, we use
chain-of-thought prompts to introduce structures from probabilistic models into
LLMs. We explore this approach in the case of metaphor understanding. Our
chain-of-thought prompts lead language models to infer latent variables and
reason about their relationships in order to choose appropriate paraphrases for
metaphors. The latent variables and relationships chosen are informed by
theories of metaphor understanding from cognitive psychology. We apply these
prompts to the two largest versions of GPT-3 and show that they can improve
performance in a paraphrase selection task.


---

