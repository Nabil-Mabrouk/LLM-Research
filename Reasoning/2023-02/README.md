## Large language models predict human sensory judgments across six
  modalities

**Published Date:** 2023-02-02T18:32:46Z

**Link:** http://arxiv.org/pdf/2302.01308v2

**Abstract:**

  Determining the extent to which the perceptual world can be recovered from
language is a longstanding problem in philosophy and cognitive science. We show
that state-of-the-art large language models can unlock new insights into this
problem by providing a lower bound on the amount of perceptual information that
can be extracted from language. Specifically, we elicit pairwise similarity
judgments from GPT models across six psychophysical datasets. We show that the
judgments are significantly correlated with human data across all domains,
recovering well-known representations like the color wheel and pitch spiral.
Surprisingly, we find that a model (GPT-4) co-trained on vision and language
does not necessarily lead to improvements specific to the visual modality. To
study the influence of specific languages on perception, we also apply the
models to a multilingual color-naming task. We find that GPT-4 replicates
cross-linguistic variation in English and Russian illuminating the interaction
of language and perception.


---

