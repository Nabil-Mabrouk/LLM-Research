## Dissociating language and thought in large language models: a cognitive
  perspective

**Published Date:** 2023-01-16T22:41:19Z

**Link:** http://arxiv.org/pdf/2301.06627v1

**Abstract:**

  Today's large language models (LLMs) routinely generate coherent, grammatical
and seemingly meaningful paragraphs of text. This achievement has led to
speculation that these networks are -- or will soon become -- "thinking
machines", capable of performing tasks that require abstract knowledge and
reasoning. Here, we review the capabilities of LLMs by considering their
performance on two different aspects of language use: 'formal linguistic
competence', which includes knowledge of rules and patterns of a given
language, and 'functional linguistic competence', a host of cognitive abilities
required for language understanding and use in the real world. Drawing on
evidence from cognitive neuroscience, we show that formal competence in humans
relies on specialized language processing mechanisms, whereas functional
competence recruits multiple extralinguistic capacities that comprise human
thought, such as formal reasoning, world knowledge, situation modeling, and
social cognition. In line with this distinction, LLMs show impressive (although
imperfect) performance on tasks requiring formal linguistic competence, but
fail on many tests requiring functional competence. Based on this evidence, we
argue that (1) contemporary LLMs should be taken seriously as models of formal
linguistic skills; (2) models that master real-life language use would need to
incorporate or develop not only a core language module, but also multiple
non-language-specific cognitive capacities required for modeling thought.
Overall, a distinction between formal and functional linguistic competence
helps clarify the discourse surrounding LLMs' potential and provides a path
toward building models that understand and use language in human-like ways.


---

## Understanding the Effectiveness of Very Large Language Models on Dialog
  Evaluation

**Published Date:** 2023-01-27T22:02:27Z

**Link:** http://arxiv.org/pdf/2301.12004v1

**Abstract:**

  Language models have steadily increased in size over the past few years. They
achieve a high level of performance on various natural language processing
(NLP) tasks such as question answering and summarization. Large language models
(LLMs) have been used for generation and can now output human-like text. Due to
this, there are other downstream tasks in the realm of dialog that can now
harness the LLMs' language understanding capabilities. Dialog evaluation is one
task that this paper will explore. It concentrates on prompting with LLMs:
BLOOM, OPT, GPT-3, Flan-T5, InstructDial and TNLGv2. The paper shows that the
choice of datasets used for training a model contributes to how well it
performs on a task as well as on how the prompt should be structured.
Specifically, the more diverse and relevant the group of datasets that a model
is trained on, the better dialog evaluation performs. This paper also
investigates how the number of examples in the prompt and the type of example
selection used affect the model's performance.


---

