## Algorithmic Ghost in the Research Shell: Large Language Models and
  Academic Knowledge Creation in Management Research

**Published Date:** 2023-03-10T14:25:29Z

**Link:** http://arxiv.org/pdf/2303.07304v1

**Abstract:**

  The paper looks at the role of large language models in academic knowledge
creation based on a scoping review (2018 to January 2023) of how researchers
have previously used the language model GPT to assist in the performance of
academic knowledge creation tasks beyond data analysis. These tasks include
writing, editing, reviewing, dataset creation and curation, which have been
difficult to perform using earlier ML tools. Based on a synthesis of these
papers, this study identifies pathways for a future academic research landscape
that incorporates wider usage of large language models based on the current
modes of adoption in published articles as a Co-Writer, Research Assistant and
Respondent.


---

## PaLM-E: An Embodied Multimodal Language Model

**Published Date:** 2023-03-06T18:58:06Z

**Link:** http://arxiv.org/pdf/2303.03378v1

**Abstract:**

  Large language models excel at a wide range of complex tasks. However,
enabling general inference in the real world, e.g., for robotics problems,
raises the challenge of grounding. We propose embodied language models to
directly incorporate real-world continuous sensor modalities into language
models and thereby establish the link between words and percepts. Input to our
embodied language model are multi-modal sentences that interleave visual,
continuous state estimation, and textual input encodings. We train these
encodings end-to-end, in conjunction with a pre-trained large language model,
for multiple embodied tasks including sequential robotic manipulation planning,
visual question answering, and captioning. Our evaluations show that PaLM-E, a
single large embodied multimodal model, can address a variety of embodied
reasoning tasks, from a variety of observation modalities, on multiple
embodiments, and further, exhibits positive transfer: the model benefits from
diverse joint training across internet-scale language, vision, and
visual-language domains. Our largest model, PaLM-E-562B with 562B parameters,
in addition to being trained on robotics tasks, is a visual-language generalist
with state-of-the-art performance on OK-VQA, and retains generalist language
capabilities with increasing scale.


---

## Answering Questions Over Knowledge Graphs Using Logic Programming Along
  with Language Models

**Published Date:** 2023-03-03T20:35:38Z

**Link:** http://arxiv.org/pdf/2303.02206v1

**Abstract:**

  Question Answering over Knowledge Graphs (KGQA) is the task of answering
natural language questions over a knowledge graph (KG). This task requires a
model to reason over multiple edges of the KG to reach the right answer. In
this work, we present a method to equip large language models (LLMs) with
classic logical programming languages to provide an explainable solution to the
problem. Our goal is to extract the representation of the question in the form
of a Prolog query, which can then be used to answer the query programmatically.
To demonstrate the effectiveness of this approach, we use the MetaQA dataset
and show that our method finds the correct answer entities for all the
questions in the test dataset.


---

## Language Model Behavior: A Comprehensive Survey

**Published Date:** 2023-03-20T23:54:26Z

**Link:** http://arxiv.org/pdf/2303.11504v1

**Abstract:**

  Transformer language models have received widespread public attention, yet
their generated text is often surprising even to NLP researchers. In this
survey, we discuss over 250 recent studies of English language model behavior
before task-specific fine-tuning. Language models possess basic capabilities in
syntax, semantics, pragmatics, world knowledge, and reasoning, but these
capabilities are sensitive to specific inputs and surface features. Despite
dramatic increases in generated text quality as models scale to hundreds of
billions of parameters, the models are still prone to unfactual responses,
commonsense errors, memorized text, and social biases. Many of these weaknesses
can be framed as over-generalizations or under-generalizations of learned
patterns in text. We synthesize recent results to highlight what is currently
known about what large language models can and cannot do.


---

