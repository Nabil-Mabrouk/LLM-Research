## Can Large Language Models design a Robot?

**Published Date:** 2023-03-15T09:41:44Z

**Link:** http://arxiv.org/pdf/2303.15324v1

**Abstract:**

  Large Language Models can lead researchers in the design of robots.


---

## Investigating the Translation Performance of a Large Multilingual
  Language Model: the Case of BLOOM

**Published Date:** 2023-03-03T13:23:42Z

**Link:** http://arxiv.org/pdf/2303.01911v2

**Abstract:**

  The NLP community recently saw the release of a new large open-access
multilingual language model, BLOOM (BigScience et al., 2022) covering 46
languages. We focus on BLOOM's multilingual ability by evaluating its machine
translation performance across several datasets (WMT, Flores-101 and DiaBLa)
and language pairs (high- and low-resourced). Our results show that 0-shot
performance suffers from overgeneration and generating in the wrong language,
but this is greatly improved in the few-shot setting, with very good results
for a number of language pairs. We study several aspects including prompt
design, model sizes, cross-lingual transfer and the use of discursive context.


---

## Domain-adapted large language models for classifying nuclear medicine
  reports

**Published Date:** 2023-03-01T09:48:39Z

**Link:** http://arxiv.org/pdf/2303.01258v1

**Abstract:**

  With the growing use of transformer-based language models in medicine, it is
unclear how well these models generalize to nuclear medicine which has
domain-specific vocabulary and unique reporting styles. In this study, we
evaluated the value of domain adaptation in nuclear medicine by adapting
language models for the purpose of 5-point Deauville score prediction based on
clinical 18F-fluorodeoxyglucose (FDG) PET/CT reports. We retrospectively
retrieved 4542 text reports and 1664 images for FDG PET/CT lymphoma exams from
2008-2018 in our clinical imaging database. Deauville scores were removed from
the reports and then the remaining text in the reports was used as the model
input. Multiple general-purpose transformer language models were used to
classify the reports into Deauville scores 1-5. We then adapted the models to
the nuclear medicine domain using masked language modeling and assessed its
impact on classification performance. The language models were compared against
vision models, a multimodal vision language model, and a nuclear medicine
physician with seven-fold Monte Carlo cross validation, reported are the mean
and standard deviations. Domain adaption improved all language models. For
example, BERT improved from 61.3% five-class accuracy to 65.7% following domain
adaptation. The best performing model (domain-adapted RoBERTa) achieved a
five-class accuracy of 77.4%, which was better than the physician's performance
(66%), the best vision model's performance (48.1), and was similar to the
multimodal model's performance (77.2). Domain adaptation improved the
performance of large language models in interpreting nuclear medicine text
reports.


---

## Scaling Expert Language Models with Unsupervised Domain Discovery

**Published Date:** 2023-03-24T17:38:58Z

**Link:** http://arxiv.org/pdf/2303.14177v1

**Abstract:**

  Large language models are typically trained densely: all parameters are
updated with respect to all inputs. This requires synchronization of billions
of parameters across thousands of GPUs. We introduce a simple but effective
method to asynchronously train large, sparse language models on arbitrary text
corpora. Our method clusters a corpus into sets of related documents, trains a
separate expert language model on each cluster, and combines them in a sparse
ensemble for inference. This approach generalizes embarrassingly parallel
training by automatically discovering the domains for each expert, and
eliminates nearly all the communication overhead of existing sparse language
models. Our technique outperforms dense baselines on multiple corpora and
few-shot tasks, and our analysis shows that specializing experts to meaningful
clusters is key to these gains. Performance also improves with the number of
experts and size of training data, suggesting this is a highly efficient and
accessible approach to training large language models.


---

## How well do Large Language Models perform in Arithmetic tasks?

**Published Date:** 2023-03-16T09:28:15Z

**Link:** http://arxiv.org/pdf/2304.02015v1

**Abstract:**

  Large language models have emerged abilities including chain-of-thought to
answer math word problems step by step. Solving math word problems not only
requires abilities to disassemble problems via chain-of-thought but also needs
to calculate arithmetic expressions correctly for each step. To the best of our
knowledge, there is no work to focus on evaluating the arithmetic ability of
large language models. In this work, we propose an arithmetic dataset MATH 401
to test the latest large language models including GPT-4, ChatGPT, InstrctGPT,
Galactica, and LLaMA with various arithmetic expressions and provide a detailed
analysis of the ability of large language models. MATH 401 and evaluation codes
are released at \url{https://github.com/GanjinZero/math401-llm}.


---

## Almanac: Retrieval-Augmented Language Models for Clinical Medicine

**Published Date:** 2023-03-01T02:30:11Z

**Link:** http://arxiv.org/pdf/2303.01229v2

**Abstract:**

  Large-language models have recently demonstrated impressive zero-shot
capabilities in a variety of natural language tasks such as summarization,
dialogue generation, and question-answering. Despite many promising
applications in clinical medicine, adoption of these models in real-world
settings has been largely limited by their tendency to generate incorrect and
sometimes even toxic statements. In this study, we develop Almanac, a large
language model framework augmented with retrieval capabilities for medical
guideline and treatment recommendations. Performance on a novel dataset of
clinical scenarios (n = 130) evaluated by a panel of 5 board-certified and
resident physicians demonstrates significant increases in factuality (mean of
18% at p-value < 0.05) across all specialties, with improvements in
completeness and safety. Our results demonstrate the potential for large
language models to be effective tools in the clinical decision-making process,
while also emphasizing the importance of careful testing and deployment to
mitigate their shortcomings.


---

## Scaling Vision-Language Models with Sparse Mixture of Experts

**Published Date:** 2023-03-13T16:00:31Z

**Link:** http://arxiv.org/pdf/2303.07226v1

**Abstract:**

  The field of natural language processing (NLP) has made significant strides
in recent years, particularly in the development of large-scale vision-language
models (VLMs). These models aim to bridge the gap between text and visual
information, enabling a more comprehensive understanding of multimedia data.
However, as these models become larger and more complex, they also become more
challenging to train and deploy. One approach to addressing this challenge is
the use of sparsely-gated mixture-of-experts (MoE) techniques, which divide the
model into smaller, specialized sub-models that can jointly solve a task. In
this paper, we explore the effectiveness of MoE in scaling vision-language
models, demonstrating its potential to achieve state-of-the-art performance on
a range of benchmarks over dense models of equivalent computational cost. Our
research offers valuable insights into stabilizing the training of MoE models,
understanding the impact of MoE on model interpretability, and balancing the
trade-offs between compute performance when scaling VLMs. We hope our work will
inspire further research into the use of MoE for scaling large-scale
vision-language models and other multimodal machine learning applications.


---

## The Impact of Large Language Multi-Modal Models on the Future of Job
  Market

**Published Date:** 2023-03-22T16:33:57Z

**Link:** http://arxiv.org/pdf/2304.06123v1

**Abstract:**

  The rapid advancements in artificial intelligence, particularly in large
language multi-modal models like GPT-4, have raised concerns about the
potential displacement of human workers in various industries. This position
paper aims to analyze the current state of job replacement by AI models and
explores potential implications and strategies for a balanced coexistence
between AI and human workers.


---

## Comparative Analysis of CHATGPT and the evolution of language models

**Published Date:** 2023-03-28T03:11:28Z

**Link:** http://arxiv.org/pdf/2304.02468v1

**Abstract:**

  Interest in Large Language Models (LLMs) has increased drastically since the
emergence of ChatGPT and the outstanding positive societal response to the ease
with which it performs tasks in Natural Language Processing (NLP). The triumph
of ChatGPT, however, is how it seamlessly bridges the divide between language
generation and knowledge models. In some cases, it provides anecdotal evidence
of a framework for replicating human intuition over a knowledge domain. This
paper highlights the prevailing ideas in NLP, including machine translation,
machine summarization, question-answering, and language generation, and
compares the performance of ChatGPT with the major algorithms in each of these
categories using the Spontaneous Quality (SQ) score. A strategy for validating
the arguments and results of ChatGPT is presented summarily as an example of
safe, large-scale adoption of LLMs.


---

## TextMI: Textualize Multimodal Information for Integrating Non-verbal
  Cues in Pre-trained Language Models

**Published Date:** 2023-03-27T17:54:32Z

**Link:** http://arxiv.org/pdf/2303.15430v2

**Abstract:**

  Pre-trained large language models have recently achieved ground-breaking
performance in a wide variety of language understanding tasks. However, the
same model can not be applied to multimodal behavior understanding tasks (e.g.,
video sentiment/humor detection) unless non-verbal features (e.g., acoustic and
visual) can be integrated with language. Jointly modeling multiple modalities
significantly increases the model complexity, and makes the training process
data-hungry. While an enormous amount of text data is available via the web,
collecting large-scale multimodal behavioral video datasets is extremely
expensive, both in terms of time and money. In this paper, we investigate
whether large language models alone can successfully incorporate non-verbal
information when they are presented in textual form. We present a way to
convert the acoustic and visual information into corresponding textual
descriptions and concatenate them with the spoken text. We feed this augmented
input to a pre-trained BERT model and fine-tune it on three downstream
multimodal tasks: sentiment, humor, and sarcasm detection. Our approach,
TextMI, significantly reduces model complexity, adds interpretability to the
model's decision, and can be applied for a diverse set of tasks while achieving
superior (multimodal sarcasm detection) or near SOTA (multimodal sentiment
analysis and multimodal humor detection) performance. We propose TextMI as a
general, competitive baseline for multimodal behavioral analysis tasks,
particularly in a low-resource setting.


---

## Letz Translate: Low-Resource Machine Translation for Luxembourgish

**Published Date:** 2023-03-02T15:26:46Z

**Link:** http://arxiv.org/pdf/2303.01347v1

**Abstract:**

  Natural language processing of Low-Resource Languages (LRL) is often
challenged by the lack of data. Therefore, achieving accurate machine
translation (MT) in a low-resource environment is a real problem that requires
practical solutions. Research in multilingual models have shown that some LRLs
can be handled with such models. However, their large size and computational
needs make their use in constrained environments (e.g., mobile/IoT devices or
limited/old servers) impractical. In this paper, we address this problem by
leveraging the power of large multilingual MT models using knowledge
distillation. Knowledge distillation can transfer knowledge from a large and
complex teacher model to a simpler and smaller student model without losing
much in performance. We also make use of high-resource languages that are
related or share the same linguistic root as the target LRL. For our
evaluation, we consider Luxembourgish as the LRL that shares some roots and
properties with German. We build multiple resource-efficient models based on
German, knowledge distillation from the multilingual No Language Left Behind
(NLLB) model, and pseudo-translation. We find that our efficient models are
more than 30\% faster and perform only 4\% lower compared to the large
state-of-the-art NLLB model.


---

## eP-ALM: Efficient Perceptual Augmentation of Language Models

**Published Date:** 2023-03-20T19:20:34Z

**Link:** http://arxiv.org/pdf/2303.11403v2

**Abstract:**

  Large Language Models (LLMs) have so far impressed the world, with
unprecedented capabilities that emerge in models at large scales. On the vision
side, transformer models (i.e., ViT) are following the same trend, achieving
the best performance on challenging benchmarks. With the abundance of such
unimodal models, a natural question arises; do we need also to follow this
trend to tackle multimodal tasks? In this work, we propose to rather direct
effort to efficient adaptations of existing models, and propose to augment
Language Models with perception. Existing approaches for adapting pretrained
models for vision-language tasks still rely on several key components that
hinder their efficiency. In particular, they still train a large number of
parameters, rely on large multimodal pretraining, use encoders (e.g., CLIP)
trained on huge image-text datasets, and add significant inference overhead. In
addition, most of these approaches have focused on Zero-Shot and In Context
Learning, with little to no effort on direct finetuning. We investigate the
minimal computational effort needed to adapt unimodal models for multimodal
tasks and propose a new challenging setup, alongside different approaches, that
efficiently adapts unimodal pretrained models. We show that by freezing more
than 99\% of total parameters, training only one linear projection layer, and
prepending only one trainable token, our approach (dubbed eP-ALM) significantly
outperforms other baselines on VQA and Captioning across Image, Video, and
Audio modalities, following the proposed setup. The code will be available
here: https://github.com/mshukor/eP-ALM.


---

## Larger language models do in-context learning differently

**Published Date:** 2023-03-07T12:24:17Z

**Link:** http://arxiv.org/pdf/2303.03846v2

**Abstract:**

  We study how in-context learning (ICL) in language models is affected by
semantic priors versus input-label mappings. We investigate two setups-ICL with
flipped labels and ICL with semantically-unrelated labels-across various model
families (GPT-3, InstructGPT, Codex, PaLM, and Flan-PaLM). First, experiments
on ICL with flipped labels show that overriding semantic priors is an emergent
ability of model scale. While small language models ignore flipped labels
presented in-context and thus rely primarily on semantic priors from
pretraining, large models can override semantic priors when presented with
in-context exemplars that contradict priors, despite the stronger semantic
priors that larger models may hold. We next study semantically-unrelated label
ICL (SUL-ICL), in which labels are semantically unrelated to their inputs
(e.g., foo/bar instead of negative/positive), thereby forcing language models
to learn the input-label mappings shown in in-context exemplars in order to
perform the task. The ability to do SUL-ICL also emerges primarily with scale,
and large-enough language models can even perform linear classification in a
SUL-ICL setting. Finally, we evaluate instruction-tuned models and find that
instruction tuning strengthens both the use of semantic priors and the capacity
to learn input-label mappings, but more of the former.


---

## ChatGPT and a New Academic Reality: Artificial Intelligence-Written
  Research Papers and the Ethics of the Large Language Models in Scholarly
  Publishing

**Published Date:** 2023-03-21T14:35:07Z

**Link:** http://arxiv.org/pdf/2303.13367v2

**Abstract:**

  This paper discusses OpenAIs ChatGPT, a generative pre-trained transformer,
which uses natural language processing to fulfill text-based user requests
(i.e., a chatbot). The history and principles behind ChatGPT and similar models
are discussed. This technology is then discussed in relation to its potential
impact on academia and scholarly research and publishing. ChatGPT is seen as a
potential model for the automated preparation of essays and other types of
scholarly manuscripts. Potential ethical issues that could arise with the
emergence of large language models like GPT-3, the underlying technology behind
ChatGPT, and its usage by academics and researchers, are discussed and situated
within the context of broader advancements in artificial intelligence, machine
learning, and natural language processing for research and scholarly
publishing.


---

