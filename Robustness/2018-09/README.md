## Multilingual Extractive Reading Comprehension by Runtime Machine
  Translation

**Published Date:** 2018-09-10T12:41:21Z

**Link:** http://arxiv.org/pdf/1809.03275v2

**Abstract:**

  Despite recent work in Reading Comprehension (RC), progress has been mostly
limited to English due to the lack of large-scale datasets in other languages.
In this work, we introduce the first RC system for languages without RC
training data. Given a target language without RC training data and a pivot
language with RC training data (e.g. English), our method leverages existing RC
resources in the pivot language by combining a competitive RC model in the
pivot language with an attentive Neural Machine Translation (NMT) model. We
first translate the data from the target to the pivot language, and then obtain
an answer using the RC model in the pivot language. Finally, we recover the
corresponding answer in the original language using soft-alignment attention
scores from the NMT model. We create evaluation sets of RC data in two
non-English languages, namely Japanese and French, to evaluate our method.
Experimental results on these datasets show that our method significantly
outperforms a back-translation baseline of a state-of-the-art product-level
machine translation system.


---

## Multitask and Multilingual Modelling for Lexical Analysis

**Published Date:** 2018-09-07T12:07:59Z

**Link:** http://arxiv.org/pdf/1809.02428v1

**Abstract:**

  In Natural Language Processing (NLP), one traditionally considers a single
task (e.g. part-of-speech tagging) for a single language (e.g. English) at a
time. However, recent work has shown that it can be beneficial to take
advantage of relatedness between tasks, as well as between languages. In this
work I examine the concept of relatedness and explore how it can be utilised to
build NLP models that require less manually annotated data. A large selection
of NLP tasks is investigated for a substantial language sample comprising 60
languages. The results show potential for joint multitask and multilingual
modelling, and hints at linguistic insights which can be gained from such
models.


---

