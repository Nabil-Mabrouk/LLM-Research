## Phoneme-level speech and natural language intergration for agglutinative
  languages

**Published Date:** 1994-11-05T06:22:31Z

**Link:** http://arxiv.org/pdf/cmp-lg/9411013v1

**Abstract:**

  A new tightly coupled speech and natural language integration model is
presented for a TDNN-based large vocabulary continuous speech recognition
system. Unlike the popular n-best techniques developed for integrating mainly
HMM-based speech and natural language systems in word level, which is obviously
inadequate for the morphologically complex agglutinative languages, our model
constructs a spoken language system based on the phoneme-level integration. The
TDNN-CYK spoken language architecture is designed and implemented using the
TDNN-based diphone recognition module integrated with the table-driven
phonological/morphological co-analysis. Our integration model provides a
seamless integration of speech and natural language for connectionist speech
recognition systems especially for morphologically complex languages such as
Korean. Our experiment results show that the speaker-dependent continuous
Eojeol (word) recognition can be integrated with the morphological analysis
with over 80\% morphological analysis success rate directly from the speech
input for the middle-level vocabularies.


---

