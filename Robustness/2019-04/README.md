## Zero-Shot Cross-Lingual Opinion Target Extraction

**Published Date:** 2019-04-19T08:59:13Z

**Link:** http://arxiv.org/pdf/1904.09122v1

**Abstract:**

  Aspect-based sentiment analysis involves the recognition of so called opinion
target expressions (OTEs). To automatically extract OTEs, supervised learning
algorithms are usually employed which are trained on manually annotated
corpora. The creation of these corpora is labor-intensive and sufficiently
large datasets are therefore usually only available for a very narrow selection
of languages and domains. In this work, we address the lack of available
annotated data for specific languages by proposing a zero-shot cross-lingual
approach for the extraction of opinion target expressions. We leverage
multilingual word embeddings that share a common vector space across various
languages and incorporate these into a convolutional neural network
architecture for OTE extraction. Our experiments with 5 languages give
promising results: We can successfully train a model on annotated data of a
source language and perform accurate prediction on a target language without
ever using any annotated samples in that target language. Depending on the
source and target language pairs, we reach performances in a zero-shot regime
of up to 77% of a model trained on target language data. Furthermore, we can
increase this performance up to 87% of a baseline model trained on target
language data by performing cross-lingual learning from multiple source
languages.


---

## Subword-Level Language Identification for Intra-Word Code-Switching

**Published Date:** 2019-04-03T13:08:12Z

**Link:** http://arxiv.org/pdf/1904.01989v1

**Abstract:**

  Language identification for code-switching (CS), the phenomenon of
alternating between two or more languages in conversations, has traditionally
been approached under the assumption of a single language per token. However,
if at least one language is morphologically rich, a large number of words can
be composed of morphemes from more than one language (intra-word CS). In this
paper, we extend the language identification task to the subword-level, such
that it includes splitting mixed words while tagging each part with a language
ID. We further propose a model for this task, which is based on a segmental
recurrent neural network. In experiments on a new Spanish--Wixarika dataset and
on an adapted German--Turkish dataset, our proposed model performs slightly
better than or roughly on par with our best baseline, respectively. Considering
only mixed words, however, it strongly outperforms all baselines.


---

