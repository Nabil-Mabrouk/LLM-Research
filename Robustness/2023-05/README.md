## How Good are Commercial Large Language Models on African Languages?

**Published Date:** 2023-05-11T02:29:53Z

**Link:** http://arxiv.org/pdf/2305.06530v1

**Abstract:**

  Recent advancements in Natural Language Processing (NLP) has led to the
proliferation of large pretrained language models. These models have been shown
to yield good performance, using in-context learning, even on unseen tasks and
languages. They have also been exposed as commercial APIs as a form of
language-model-as-a-service, with great adoption. However, their performance on
African languages is largely unknown. We present a preliminary analysis of
commercial large language models on two tasks (machine translation and text
classification) across eight African languages, spanning different language
families and geographical areas. Our results suggest that commercial language
models produce below-par performance on African languages. We also find that
they perform better on text classification than machine translation. In
general, our findings present a call-to-action to ensure African languages are
well represented in commercial large language models, given their growing
popularity.


---

## Images in Language Space: Exploring the Suitability of Large Language
  Models for Vision & Language Tasks

**Published Date:** 2023-05-23T07:50:36Z

**Link:** http://arxiv.org/pdf/2305.13782v1

**Abstract:**

  Large language models have demonstrated robust performance on various
language tasks using zero-shot or few-shot learning paradigms. While being
actively researched, multimodal models that can additionally handle images as
input have yet to catch up in size and generality with language-only models. In
this work, we ask whether language-only models can be utilised for tasks that
require visual input -- but also, as we argue, often require a strong reasoning
component. Similar to some recent related work, we make visual information
accessible to the language model using separate verbalisation models.
Specifically, we investigate the performance of open-source, open-access
language models against GPT-3 on five vision-language tasks when given
textually-encoded visual information. Our results suggest that language models
are effective for solving vision-language tasks even with limited samples. This
approach also enhances the interpretability of a model's output by providing a
means of tracing the output back through the verbalised image content.


---

## BigTranslate: Augmenting Large Language Models with Multilingual
  Translation Capability over 100 Languages

**Published Date:** 2023-05-29T14:07:52Z

**Link:** http://arxiv.org/pdf/2305.18098v2

**Abstract:**

  Large language models (LLMs) demonstrate promising translation performance
among various natural languages. However, many LLMs especially the open-sourced
ones, such as BLOOM and LLaMA, are English-dominant and support only dozens of
natural languages, making the potential of LLMs on language translation less
explored. In this work, we present BigTranslate which adapts LLaMA that covers
only 20 languages and enhances it with multilingual translation capability on
more than 100 languages. BigTranslate is built upon LLaMA-13B and it is
optimized in three steps. First, we continue training LLaMA with massive
Chinese monolingual data. Second, we continue training the model with a
large-scale parallel dataset that covers 102 natural languages. Third, we
instruct-tune the foundation model with multilingual translation instructions,
leading to our BigTranslate model. The preliminary experiments on multilingual
translation show that BigTranslate performs comparably with ChatGPT and Google
Translate in many languages and even outperforms ChatGPT in 8 language pairs.
We release the BigTranslate model and hope it can advance the research
progress.


---

## Do All Languages Cost the Same? Tokenization in the Era of Commercial
  Language Models

**Published Date:** 2023-05-23T05:46:45Z

**Link:** http://arxiv.org/pdf/2305.13707v1

**Abstract:**

  Language models have graduated from being research prototypes to
commercialized products offered as web APIs, and recent works have highlighted
the multilingual capabilities of these products. The API vendors charge their
users based on usage, more specifically on the number of ``tokens'' processed
or generated by the underlying language models. What constitutes a token,
however, is training data and model dependent with a large variance in the
number of tokens required to convey the same information in different
languages. In this work, we analyze the effect of this non-uniformity on the
fairness of an API's pricing policy across languages. We conduct a systematic
analysis of the cost and utility of OpenAI's language model API on multilingual
benchmarks in 22 typologically diverse languages. We show evidence that
speakers of a large number of the supported languages are overcharged while
obtaining poorer results. These speakers tend to also come from regions where
the APIs are less affordable to begin with. Through these analyses, we aim to
increase transparency around language model APIs' pricing policies and
encourage the vendors to make them more equitable.


---

## How do languages influence each other? Studying cross-lingual data
  sharing during LLM fine-tuning

**Published Date:** 2023-05-22T17:47:41Z

**Link:** http://arxiv.org/pdf/2305.13286v1

**Abstract:**

  Multilingual large language models (MLLMs) are jointly trained on data from
many different languages such that representation of individual languages can
benefit from other languages' data. Impressive performance on zero-shot
cross-lingual transfer shows that these models are capable of exploiting data
from other languages. Yet, it remains unclear to what extent, and under which
conditions, languages rely on each other's data. In this study, we use TracIn
(Pruthi et al., 2020), a training data attribution (TDA) method, to retrieve
the most influential training samples seen during multilingual fine-tuning for
a particular test language. This allows us to analyse cross-lingual sharing
mechanisms of MLLMs from a new perspective. While previous work studied
cross-lingual sharing at the level of model parameters, we present the first
approach to study cross-lingual sharing at the data level. We find that MLLMs
rely on data from multiple languages from the early stages of fine-tuning and
that this reliance gradually increases as fine-tuning progresses. We further
study how different fine-tuning languages influence model performance on a
given test language and find that they can both reinforce and complement the
knowledge acquired from data of the test language itself.


---

## LIMIT: Language Identification, Misidentification, and Translation using
  Hierarchical Models in 350+ Languages

**Published Date:** 2023-05-23T17:15:43Z

**Link:** http://arxiv.org/pdf/2305.14263v1

**Abstract:**

  Knowing the language of an input text/audio is a necessary first step for
using almost every natural language processing (NLP) tool such as taggers,
parsers, or translation systems. Language identification is a well-studied
problem, sometimes even considered solved; in reality, most of the world's 7000
languages are not supported by current systems. This lack of representation
affects large-scale data mining efforts and further exacerbates data shortage
for low-resource languages. We take a step towards tackling the data bottleneck
by compiling a corpus of over 50K parallel children's stories in 350+ languages
and dialects, and the computation bottleneck by building lightweight
hierarchical models for language identification. Our data can serve as
benchmark data for language identification of short texts and for understudied
translation directions such as those between Indian or African languages. Our
proposed method, Hierarchical LIMIT, uses limited computation to expand
coverage into excluded languages while maintaining prediction quality.


---

## DN at SemEval-2023 Task 12: Low-Resource Language Text Classification
  via Multilingual Pretrained Language Model Fine-tuning

**Published Date:** 2023-05-04T07:28:45Z

**Link:** http://arxiv.org/pdf/2305.02607v1

**Abstract:**

  In recent years, sentiment analysis has gained significant importance in
natural language processing. However, most existing models and datasets for
sentiment analysis are developed for high-resource languages, such as English
and Chinese, leaving low-resource languages, particularly African languages,
largely unexplored. The AfriSenti-SemEval 2023 Shared Task 12 aims to fill this
gap by evaluating sentiment analysis models on low-resource African languages.
In this paper, we present our solution to the shared task, where we employed
different multilingual XLM-R models with classification head trained on various
data, including those retrained in African dialects and fine-tuned on target
languages. Our team achieved the third-best results in Subtask B, Track 16:
Multilingual, demonstrating the effectiveness of our approach. While our model
showed relatively good results on multilingual data, it performed poorly in
some languages. Our findings highlight the importance of developing more
comprehensive datasets and models for low-resource African languages to advance
sentiment analysis research. We also provided the solution on the github
repository.


---

## Instruct-Align: Teaching Novel Languages with to LLMs through
  Alignment-based Cross-Lingual Instruction

**Published Date:** 2023-05-23T02:51:34Z

**Link:** http://arxiv.org/pdf/2305.13627v1

**Abstract:**

  Instruction-tuned large language models (LLMs) have shown remarkable
generalization capability over multiple tasks in multiple languages.
Nevertheless, their generalization towards different languages varies
especially to underrepresented languages or even to unseen languages. Prior
works on adapting new languages to LLMs find that naively adapting new
languages to instruction-tuned LLMs will result in catastrophic forgetting,
which in turn causes the loss of multitasking ability in these LLMs. To tackle
this, we propose the Instruct-Align a.k.a (IA)$^1$ framework, which enables
instruction-tuned LLMs to learn cross-lingual alignment between unseen and
previously learned languages via alignment-based cross-lingual
instruction-tuning. Our preliminary result on BLOOMZ-560M shows that (IA)$^1$
is able to learn a new language effectively with only a limited amount of
parallel data and at the same time prevent catastrophic forgetting by applying
continual instruction-tuning through experience replay. Our work contributes to
the progression of language adaptation methods for instruction-tuned LLMs and
opens up the possibility of adapting underrepresented low-resource languages
into existing instruction-tuned LLMs. Our code will be publicly released upon
acceptance.


---

## mmT5: Modular Multilingual Pre-Training Solves Source Language
  Hallucinations

**Published Date:** 2023-05-23T16:38:01Z

**Link:** http://arxiv.org/pdf/2305.14224v1

**Abstract:**

  Multilingual sequence-to-sequence models perform poorly with increased
language coverage and fail to consistently generate text in the correct target
language in few-shot settings. To address these challenges, we propose mmT5, a
modular multilingual sequence-to-sequence model. mmT5 utilizes
language-specific modules during pre-training, which disentangle
language-specific information from language-agnostic information. We identify
representation drift during fine-tuning as a key limitation of modular
generative models and develop strategies that enable effective zero-shot
transfer. Our model outperforms mT5 at the same parameter sizes by a large
margin on representative natural language understanding and generation tasks in
40+ languages. Compared to mT5, mmT5 raises the rate of generating text in the
correct language under zero-shot settings from 7% to 99%, thereby greatly
alleviating the source language hallucination problem.


---

## Autocorrelations Decay in Texts and Applicability Limits of Language
  Models

**Published Date:** 2023-05-11T07:23:01Z

**Link:** http://arxiv.org/pdf/2305.06615v1

**Abstract:**

  We show that the laws of autocorrelations decay in texts are closely related
to applicability limits of language models. Using distributional semantics we
empirically demonstrate that autocorrelations of words in texts decay according
to a power law. We show that distributional semantics provides coherent
autocorrelations decay exponents for texts translated to multiple languages.
The autocorrelations decay in generated texts is quantitatively and often
qualitatively different from the literary texts. We conclude that language
models exhibiting Markov behavior, including large autoregressive language
models, may have limitations when applied to long texts, whether analysis or
generation.


---

## FreeLM: Fine-Tuning-Free Language Model

**Published Date:** 2023-05-02T17:17:56Z

**Link:** http://arxiv.org/pdf/2305.01616v1

**Abstract:**

  Pre-trained language models (PLMs) have achieved remarkable success in NLP
tasks. Despite the great success, mainstream solutions largely follow the
pre-training then finetuning paradigm, which brings in both high deployment
costs and low training efficiency. Nevertheless, fine-tuning on a specific task
is essential because PLMs are only pre-trained with language signal from large
raw data. In this paper, we propose a novel fine-tuning-free strategy for
language models, to consider both language signal and teacher signal. Teacher
signal is an abstraction of a battery of downstream tasks, provided in a
unified proposition format. Trained with both language and strong task-aware
teacher signals in an interactive manner, our FreeLM model demonstrates strong
generalization and robustness. FreeLM outperforms large models e.g., GPT-3 and
InstructGPT, on a range of language understanding tasks in experiments. FreeLM
is much smaller with 0.3B parameters, compared to 175B in these models.


---

## Train Global, Tailor Local: Minimalist Multilingual Translation into
  Endangered Languages

**Published Date:** 2023-05-05T23:22:16Z

**Link:** http://arxiv.org/pdf/2305.03873v1

**Abstract:**

  In many humanitarian scenarios, translation into severely low resource
languages often does not require a universal translation engine, but a
dedicated text-specific translation engine. For example, healthcare records,
hygienic procedures, government communication, emergency procedures and
religious texts are all limited texts. While generic translation engines for
all languages do not exist, translation of multilingually known limited texts
into new, endangered languages may be possible and reduce human translation
effort. We attempt to leverage translation resources from many rich resource
languages to efficiently produce best possible translation quality for a well
known text, which is available in multiple languages, in a new, severely low
resource language. We examine two approaches: 1. best selection of seed
sentences to jump start translations in a new language in view of best
generalization to the remainder of a larger targeted text(s), and 2. we adapt
large general multilingual translation engines from many other languages to
focus on a specific text in a new, unknown language. We find that adapting
large pretrained multilingual models to the domain/text first and then to the
severely low resource language works best. If we also select a best set of seed
sentences, we can improve average chrF performance on new test languages from a
baseline of 21.9 to 50.7, while reducing the number of seed sentences to only
around 1,000 in the new, unknown language.


---

## Decomposed Prompting for Machine Translation Between Related Languages
  using Large Language Models

**Published Date:** 2023-05-22T14:52:47Z

**Link:** http://arxiv.org/pdf/2305.13085v1

**Abstract:**

  This study investigates machine translation between related languages i.e.,
languages within the same family that share similar linguistic traits such as
word order and lexical similarity. Machine translation through few-shot
prompting leverages a small set of translation pair examples to generate
translations for test sentences. This requires the model to learn how to
generate translations while simultaneously ensuring that token ordering is
maintained to produce a fluent and accurate translation. We propose that for
related languages, the task of machine translation can be simplified by
leveraging the monotonic alignment characteristic of such languages. We
introduce a novel approach of few-shot prompting that decomposes the
translation process into a sequence of word chunk translations. Through
evaluations conducted on multiple related language pairs across various
language families, we demonstrate that our novel approach of decomposed
prompting surpasses multiple established few-shot baseline models, thereby
verifying its effectiveness. For example, our model outperforms the strong
few-shot prompting BLOOM model with an average improvement of 4.2 chrF++ scores
across the examined languages.


---

## Generating Data for Symbolic Language with Large Language Models

**Published Date:** 2023-05-23T10:44:00Z

**Link:** http://arxiv.org/pdf/2305.13917v1

**Abstract:**

  While large language models (LLMs) bring not only performance but also
complexity, recent work has started to turn LLMs into data generators rather
than task inferencers, where another affordable task model is trained for
efficient deployment and inference. However, such an approach has primarily
been applied to natural language tasks and has not yet been explored for
symbolic language tasks with complex structured outputs (e.g., semantic parsing
and code generation). In this paper, we propose SymGen which utilizes LLMs for
generating various annotation-expensive symbolic language data. SymGen consists
of an informative prompt to steer generation and an agreement-based verifier to
improve data correctness. We conduct extensive experiments on six symbolic
language tasks across various settings. Compared with the LLMs, we demonstrate
the 1\%-sized task model can achieve comparable or better performance, largely
cutting inference and deployment costs. We also show that generated data with
only a few human demonstrations can be as effective as over 10 times the amount
of human-annotated data when training the task model, saving a considerable
amount of annotation effort. SymGen sheds new light on data generation for
complex tasks, and we release the code at
\href{https://github.com/HKUNLP/SymGen}{https://github.com/HKUNLP/SymGen}.


---

## Glot500: Scaling Multilingual Corpora and Language Models to 500
  Languages

**Published Date:** 2023-05-20T12:26:41Z

**Link:** http://arxiv.org/pdf/2305.12182v2

**Abstract:**

  The NLP community has mainly focused on scaling Large Language Models (LLMs)
vertically, i.e., making them better for about 100 languages. We instead scale
LLMs horizontally: we create, through continued pretraining, Glot500-m, an LLM
that covers 511 predominantly low-resource languages. An important part of this
effort is to collect and clean Glot500-c, a corpus that covers these 511
languages and allows us to train Glot500-m. We evaluate Glot500-m on five
diverse tasks across these languages. We observe large improvements for both
high-resource and low-resource languages compared to an XLM-R baseline. Our
analysis shows that no single factor explains the quality of multilingual LLM
representations. Rather, a combination of factors determines quality including
corpus size, script, "help" from related languages and the total capacity of
the model. Our work addresses an important goal of NLP research: we should not
limit NLP to a small fraction of the world's languages and instead strive to
support as many languages as possible to bring the benefits of NLP technology
to all languages and cultures. Code, data and models are available at
https://github.com/cisnlp/Glot500.


---

## Can Large Language Models Infer and Disagree Like Humans?

**Published Date:** 2023-05-23T07:55:34Z

**Link:** http://arxiv.org/pdf/2305.13788v1

**Abstract:**

  Large Language Models (LLMs) have shown stellar achievements in solving a
broad range of tasks. When generating text, it is common to sample tokens from
these models: whether LLMs closely align with the human disagreement
distribution has not been well-studied, especially within the scope of Natural
Language Inference (NLI). In this paper, we evaluate the performance and
alignment of LLM distribution with humans using two different techniques: Monte
Carlo Reconstruction (MCR) and Log Probability Reconstruction (LPR). As a
result, we show LLMs exhibit limited ability in solving NLI tasks and
simultaneously fail to capture human disagreement distribution, raising
concerns about their natural language understanding (NLU) ability and their
representativeness of human users.


---

## Exploring Large Language Models for Classical Philology

**Published Date:** 2023-05-23T05:21:02Z

**Link:** http://arxiv.org/pdf/2305.13698v1

**Abstract:**

  Recent advances in NLP have led to the creation of powerful language models
for many languages including Ancient Greek and Latin. While prior work on
Classical languages unanimously uses BERT, in this work we create four language
models for Ancient Greek that vary along two dimensions to study their
versatility for tasks of interest for Classical languages: we explore (i)
encoder-only and encoder-decoder architectures using RoBERTa and T5 as strong
model types, and create for each of them (ii) a monolingual Ancient Greek and a
multilingual instance that includes Latin and English. We evaluate all models
on morphological and syntactic tasks, including lemmatization, which
demonstrates the added value of T5's decoding abilities. We further define two
probing tasks to investigate the knowledge acquired by models pre-trained on
Classical texts. Our experiments provide the first benchmarking analysis of
existing models of Ancient Greek. Results show that our models provide
significant improvements over the SoTA. The systematic analysis of model types
can inform future research in designing language models for Classical
languages, including the development of novel generative tasks. We make all our
models available as community resources, along with a large curated
pre-training corpus for Ancient Greek, to support the creation of a larger,
comparable model zoo for Classical Philology. Our models and resources are
available at https://github.com/Heidelberg-NLP/ancient-language-models.


---

## Chain of Knowledge: A Framework for Grounding Large Language Models with
  Structured Knowledge Bases

**Published Date:** 2023-05-22T17:34:23Z

**Link:** http://arxiv.org/pdf/2305.13269v1

**Abstract:**

  We introduce Chain of Knowledge (CoK), a framework that augments large
language models with structured knowledge bases to improve factual correctness
and reduce hallucination. Compared to previous works which only retrieve
unstructured texts, CoK leverages structured knowledge bases which support
complex queries and offer more direct factual statements. To assist large
language models to effectively query knowledge bases, we propose a query
generator model with contrastive instruction-tuning. As the query generator is
separate from the frozen large language model, our framework is modular and
thus easily adapted to various knowledge sources and models. Experiments show
that our framework significantly enhances the factual correctness of large
language models on knowledge-intensive tasks.


---

## PURR: Efficiently Editing Language Model Hallucinations by Denoising
  Language Model Corruptions

**Published Date:** 2023-05-24T08:59:00Z

**Link:** http://arxiv.org/pdf/2305.14908v1

**Abstract:**

  The remarkable capabilities of large language models have been accompanied by
a persistent drawback: the generation of false and unsubstantiated claims
commonly known as "hallucinations". To combat this issue, recent research has
introduced approaches that involve editing and attributing the outputs of
language models, particularly through prompt-based editing. However, the
inference cost and speed of using large language models for editing currently
bottleneck prompt-based methods. These bottlenecks motivate the training of
compact editors, which is challenging due to the scarcity of training data for
this purpose. To overcome these challenges, we exploit the power of large
language models to introduce corruptions (i.e., noise) into text and
subsequently fine-tune compact editors to denoise the corruptions by
incorporating relevant evidence. Our methodology is entirely unsupervised and
provides us with faux hallucinations for training in any domain. Our Petite
Unsupervised Research and Revision model, PURR, not only improves attribution
over existing editing methods based on fine-tuning and prompting, but also
achieves faster execution times by orders of magnitude.


---

## Distilling Script Knowledge from Large Language Models for Constrained
  Language Planning

**Published Date:** 2023-05-09T08:19:32Z

**Link:** http://arxiv.org/pdf/2305.05252v5

**Abstract:**

  In everyday life, humans often plan their actions by following step-by-step
instructions in the form of goal-oriented scripts. Previous work has exploited
language models (LMs) to plan for abstract goals of stereotypical activities
(e.g., "make a cake"), but leaves more specific goals with multi-facet
constraints understudied (e.g., "make a cake for diabetics"). In this paper, we
define the task of constrained language planning for the first time. We propose
an overgenerate-then-filter approach to improve large language models (LLMs) on
this task, and use it to distill a novel constrained language planning dataset,
CoScript, which consists of 55,000 scripts. Empirical results demonstrate that
our method significantly improves the constrained language planning ability of
LLMs, especially on constraint faithfulness. Furthermore, CoScript is
demonstrated to be quite effective in endowing smaller LMs with constrained
language planning ability.


---

## Meta-in-context learning in large language models

**Published Date:** 2023-05-22T10:40:36Z

**Link:** http://arxiv.org/pdf/2305.12907v1

**Abstract:**

  Large language models have shown tremendous performance in a variety of
tasks. In-context learning -- the ability to improve at a task after being
provided with a number of demonstrations -- is seen as one of the main
contributors to their success. In the present paper, we demonstrate that the
in-context learning abilities of large language models can be recursively
improved via in-context learning itself. We coin this phenomenon
meta-in-context learning. Looking at two idealized domains, a one-dimensional
regression task and a two-armed bandit task, we show that meta-in-context
learning adaptively reshapes a large language model's priors over expected
tasks. Furthermore, we find that meta-in-context learning modifies the
in-context learning strategies of such models. Finally, we extend our approach
to a benchmark of real-world regression problems where we observe competitive
performance to traditional learning algorithms. Taken together, our work
improves our understanding of in-context learning and paves the way toward
adapting large language models to the environment they are applied purely
through meta-in-context learning rather than traditional finetuning.


---

## Evaluating the Performance of Large Language Models on GAOKAO Benchmark

**Published Date:** 2023-05-21T14:39:28Z

**Link:** http://arxiv.org/pdf/2305.12474v2

**Abstract:**

  Large language models have demonstrated remarkable performance across various
natural language processing tasks; however, their efficacy in more challenging
and domain-specific tasks remains less explored. This paper introduces the
GAOKAO-Benchmark (GAOKAO-Bench), an intuitive benchmark that employs questions
from the Chinese Gaokao examination as test samples for evaluating large
language models.In order to align the evaluation results with humans as much as
possible, we designed a method based on zero-shot prompts to analyze the
accuracy and scoring rate of the model by dividing the questions into
subjective and objective types. We evaluated the ChatGPT model on
GAOKAO-Benchmark performance.Our findings reveal that the ChatGPT model excels
in tackling objective questions, while also shedding light on its shortcomings
and areas for improvement. To further scrutinize the model's responses, we
incorporate human evaluations.In conclusion, this research contributes a robust
evaluation benchmark for future large-scale language models and offers valuable
insights into the limitations of such models.


---

## Domain Private Transformers

**Published Date:** 2023-05-23T16:27:12Z

**Link:** http://arxiv.org/pdf/2305.14208v1

**Abstract:**

  Large, general purpose language models have demonstrated impressive
performance across many different conversational domains. While multi-domain
language models achieve low overall perplexity, their outputs are not
guaranteed to stay within the domain of a given input prompt. This paper
proposes domain privacy as a novel way to quantify how likely a conditional
language model will leak across domains. We also develop policy functions based
on token-level domain classification, and propose an efficient fine-tuning
method to improve the trained model's domain privacy. Experiments on membership
inference attacks show that our proposed method has comparable resiliency to
methods adapted from recent literature on differentially private language
models.


---

## ChatBridge: Bridging Modalities with Large Language Model as a Language
  Catalyst

**Published Date:** 2023-05-25T14:34:08Z

**Link:** http://arxiv.org/pdf/2305.16103v1

**Abstract:**

  Building general-purpose models that can perceive diverse real-world
modalities and solve various tasks is an appealing target in artificial
intelligence. In this paper, we present ChatBridge, a novel multimodal language
model that leverages the expressive capabilities of language as the catalyst to
bridge the gap between various modalities. We show that only language-paired
two-modality data is sufficient to connect all modalities. ChatBridge leverages
recent large language models (LLM) and extends their zero-shot capabilities to
incorporate diverse multimodal inputs. ChatBridge undergoes a two-stage
training. The first stage aligns each modality with language, which brings
emergent multimodal correlation and collaboration abilities. The second stage
instruction-finetunes ChatBridge to align it with user intent with our newly
proposed multimodal instruction tuning dataset, named MULTIS, which covers a
wide range of 16 multimodal tasks of text, image, video, and audio modalities.
We show strong quantitative and qualitative results on zero-shot multimodal
tasks covering text, image, video, and audio modalities. All codes, data, and
models of ChatBridge will be open-sourced.


---

## Token-wise Decomposition of Autoregressive Language Model Hidden States
  for Analyzing Model Predictions

**Published Date:** 2023-05-17T23:55:32Z

**Link:** http://arxiv.org/pdf/2305.10614v2

**Abstract:**

  While there is much recent interest in studying why Transformer-based large
language models make predictions the way they do, the complex computations
performed within each layer have made their behavior somewhat opaque. To
mitigate this opacity, this work presents a linear decomposition of final
hidden states from autoregressive language models based on each initial input
token, which is exact for virtually all contemporary Transformer architectures.
This decomposition allows the definition of probability distributions that
ablate the contribution of specific input tokens, which can be used to analyze
their influence on model probabilities over a sequence of upcoming words with
only one forward pass from the model. Using the change in next-word probability
as a measure of importance, this work first examines which context words make
the biggest contribution to language model predictions. Regression experiments
suggest that Transformer-based language models rely primarily on collocational
associations, followed by linguistic factors such as syntactic dependencies and
coreference relationships in making next-word predictions. Additionally,
analyses using these measures to predict syntactic dependencies and coreferent
mention spans show that collocational association and repetitions of the same
token largely explain the language models' predictions on these tasks.


---

## Preserving Pre-trained Features Helps Calibrate Fine-tuned Language
  Models

**Published Date:** 2023-05-30T17:35:31Z

**Link:** http://arxiv.org/pdf/2305.19249v1

**Abstract:**

  Large pre-trained language models (PLMs) have demonstrated strong performance
on natural language understanding (NLU) tasks through fine-tuning. However,
fine-tuned models still suffer from overconfident predictions, especially in
out-of-domain settings. In this paper, we tackle the problem of calibrating
fine-tuned language models. We demonstrate that the PLMs are well-calibrated on
the masked language modeling task with robust predictive confidence under
domain shift, yet the fine-tuned models fail to retain such property due to
catastrophic forgetting, which impacts the calibration on the downstream
classification task. In light of these observations, we evaluate the
calibration of several methods that preserve pre-trained features and show that
preserving pre-trained features can improve the calibration of fine-tuned
language models. Among these methods, our proposed method that encourages the
fine-tuned model to learn generative representations with auxiliary language
modeling objective achieves competitive accuracy and the lowest expected
calibration error compared to several strong baselines under both in-domain and
out-of-domain settings on three downstream NLU tasks.


---

## Drafting Event Schemas using Language Models

**Published Date:** 2023-05-24T07:57:04Z

**Link:** http://arxiv.org/pdf/2305.14847v1

**Abstract:**

  Past work has studied event prediction and event language modeling, sometimes
mediated through structured representations of knowledge in the form of event
schemas. Such schemas can lead to explainable predictions and forecasting of
unseen events given incomplete information. In this work, we look at the
process of creating such schemas to describe complex events. We use large
language models (LLMs) to draft schemas directly in natural language, which can
be further refined by human curators as necessary. Our focus is on whether we
can achieve sufficient diversity and recall of key events and whether we can
produce the schemas in a sufficiently descriptive style. We show that large
language models are able to achieve moderate recall against schemas taken from
two different datasets, with even better results when multiple prompts and
multiple samples are combined. Moreover, we show that textual entailment
methods can be used for both matching schemas to instances of events as well as
evaluating overlap between gold and predicted schemas. Our method paves the way
for easier distillation of event knowledge from large language model into
schemas.


---

## Can ChatGPT Detect Intent? Evaluating Large Language Models for Spoken
  Language Understanding

**Published Date:** 2023-05-22T21:59:26Z

**Link:** http://arxiv.org/pdf/2305.13512v1

**Abstract:**

  Recently, large pretrained language models have demonstrated strong language
understanding capabilities. This is particularly reflected in their zero-shot
and in-context learning abilities on downstream tasks through prompting. To
assess their impact on spoken language understanding (SLU), we evaluate several
such models like ChatGPT and OPT of different sizes on multiple benchmarks. We
verify the emergent ability unique to the largest models as they can reach
intent classification accuracy close to that of supervised models with zero or
few shots on various languages given oracle transcripts. By contrast, the
results for smaller models fitting a single GPU fall far behind. We note that
the error cases often arise from the annotation scheme of the dataset;
responses from ChatGPT are still reasonable. We show, however, that the model
is worse at slot filling, and its performance is sensitive to ASR errors,
suggesting serious challenges for the application of those textual models on
SLU.


---

## Accessible Instruction-Following Agent

**Published Date:** 2023-05-08T23:57:26Z

**Link:** http://arxiv.org/pdf/2305.06358v1

**Abstract:**

  Humans can collaborate and complete tasks based on visual signals and
instruction from the environment. Training such a robot is difficult especially
due to the understanding of the instruction and the complicated environment.
Previous instruction-following agents are biased to English-centric corpus,
making it unrealizable to be applied to users that use multiple languages or
even low-resource languages. Nevertheless, the instruction-following agents are
pre-trained in a mode that assumes the user can observe the environment, which
limits its accessibility. In this work, we're trying to generalize the success
of instruction-following agents to non-English languages with little corpus
resources, and improve its intractability and accessibility. We introduce UVLN
(Universal Vision-Language Navigation), a novel machine-translation
instructional augmented framework for cross-lingual vision-language navigation,
with a novel composition of state-of-the-art large language model (GPT3) with
the image caption model (BLIP). We first collect a multilanguage
vision-language navigation dataset via machine translation. Then we extend the
standard VLN training objectives to a multilingual setting via a cross-lingual
language encoder. The alignment between different languages is captured through
a shared vision and action context via a cross-modal transformer, which encodes
the inputs of language instruction, visual observation, and action decision
sequences. To improve the intractability, we connect our agent with the large
language model that informs the situation and current state to the user and
also explains the action decisions. Experiments over Room Across Room Dataset
prove the effectiveness of our approach. And the qualitative results show the
promising intractability and accessibility of our instruction-following agent.


---

## Test-Time Training on Nearest Neighbors for Large Language Models

**Published Date:** 2023-05-29T08:03:28Z

**Link:** http://arxiv.org/pdf/2305.18466v2

**Abstract:**

  Many recent efforts aim to augment language models with relevant information
retrieved from a database at test time. We avoid the need for prompt
engineering by directly fine-tuning the model on data retrieved at test time
using its standard training setup. For this purpose, we build a large-scale
distributed nearest neighbor index based on text embeddings of the Pile
dataset. Given a query to a language model, our system retrieves the neighbors
of the query and fine-tunes the model on the text data corresponding to those
neighbors. Surprisingly, retrieving and training on as few as 20 neighbors,
each for only one gradient iteration, drastically improves performance across
more than twenty language modeling tasks in the Pile benchmark. For example,
test-time training significantly narrows the performance gap between a small
GPT2 model and a GPTNeo model, more than ten times larger, that was
specifically trained to convergence on the Pile. Sufficient index quality and
size, however, are important. Our work establishes a valuable first baseline
for implementing test-time training in the context of large language models,
opening the door to numerous promising research avenues.


---

## Retentive or Forgetful? Diving into the Knowledge Memorizing Mechanism
  of Language Models

**Published Date:** 2023-05-16T03:50:38Z

**Link:** http://arxiv.org/pdf/2305.09144v1

**Abstract:**

  Memory is one of the most essential cognitive functions serving as a
repository of world knowledge and episodes of activities. In recent years,
large-scale pre-trained language models have shown remarkable memorizing
ability. On the contrary, vanilla neural networks without pre-training have
been long observed suffering from the catastrophic forgetting problem. To
investigate such a retentive-forgetful contradiction and understand the memory
mechanism of language models, we conduct thorough experiments by controlling
the target knowledge types, the learning strategies and the learning schedules.
We find that: 1) Vanilla language models are forgetful; 2) Pre-training leads
to retentive language models; 3) Knowledge relevance and diversification
significantly influence the memory formation. These conclusions are useful for
understanding the abilities of pre-trained language models and shed light on
designing and evaluating new learning and inference algorithms of language
models.


---

## How to Unleash the Power of Large Language Models for Few-shot Relation
  Extraction?

**Published Date:** 2023-05-02T15:55:41Z

**Link:** http://arxiv.org/pdf/2305.01555v4

**Abstract:**

  Scaling language models have revolutionized widespread NLP tasks, yet little
comprehensively explored few-shot relation extraction with large language
models. In this paper, we investigate principal methodologies, in-context
learning and data generation, for few-shot relation extraction via GPT-3.5
through exhaustive experiments. To enhance few-shot performance, we further
propose task-related instructions and schema-constrained data generation. We
observe that in-context learning can achieve performance on par with previous
prompt learning approaches, and data generation with the large language model
can boost previous solutions to obtain new state-of-the-art few-shot results on
four widely-studied relation extraction datasets. We hope our work can inspire
future research for the capabilities of large language models in few-shot
relation extraction. Code is available in
https://github.com/zjunlp/DeepKE/tree/main/example/llm.


---

## Likelihood-Based Diffusion Language Models

**Published Date:** 2023-05-30T16:43:31Z

**Link:** http://arxiv.org/pdf/2305.18619v1

**Abstract:**

  Despite a growing interest in diffusion-based language models, existing work
has not shown that these models can attain nontrivial likelihoods on standard
language modeling benchmarks. In this work, we take the first steps towards
closing the likelihood gap between autoregressive and diffusion-based language
models, with the goal of building and releasing a diffusion model which
outperforms a small but widely-known autoregressive model. We pursue this goal
through algorithmic improvements, scaling laws, and increased compute. On the
algorithmic front, we introduce several methodological improvements for the
maximum-likelihood training of diffusion language models. We then study scaling
laws for our diffusion models and find compute-optimal training regimes which
differ substantially from autoregressive models. Using our methods and scaling
analysis, we train and release Plaid 1B, a large diffusion language model which
outperforms GPT-2 124M in likelihood on benchmark datasets and generates fluent
samples in unconditional and zero-shot control settings.


---

## Eliciting the Translation Ability of Large Language Models via
  Multilingual Finetuning with Translation Instructions

**Published Date:** 2023-05-24T12:00:24Z

**Link:** http://arxiv.org/pdf/2305.15083v2

**Abstract:**

  Large-scale Pretrained Language Models (LLMs), such as ChatGPT and GPT4, have
shown strong abilities in multilingual translations, without being explicitly
trained on parallel corpora. It is interesting how the LLMs obtain their
ability to carry out translation instructions for different languages. In this
paper, we present a detailed analysis by finetuning a multilingual pretrained
language model, XGLM-7B, to perform multilingual translation following given
instructions. Firstly, we show that multilingual LLMs have stronger translation
abilities than previously demonstrated. For a certain language, the performance
depends on its similarity to English and the amount of data used in the
pretraining phase. Secondly, we find that LLMs' ability to carry out
translation instructions relies on the understanding of translation
instructions and the alignment among different languages. With multilingual
finetuning, LLMs could learn to perform the translation task well even for
those language pairs unseen during the instruction tuning phase.


---

## RewriteLM: An Instruction-Tuned Large Language Model for Text Rewriting

**Published Date:** 2023-05-25T03:26:26Z

**Link:** http://arxiv.org/pdf/2305.15685v1

**Abstract:**

  Large Language Models (LLMs) have demonstrated impressive zero-shot
capabilities in long-form text generation tasks expressed through natural
language instructions. However, user expectations for long-form text rewriting
is high, and unintended rewrites (''hallucinations'') produced by the model can
negatively impact its overall performance. Existing evaluation benchmarks
primarily focus on limited rewriting styles and sentence-level rewriting rather
than long-form open-ended rewriting.We introduce OpenRewriteEval, a novel
benchmark that covers a wide variety of rewriting types expressed through
natural language instructions. It is specifically designed to facilitate the
evaluation of open-ended rewriting of long-form texts. In addition, we propose
a strong baseline model, RewriteLM, an instruction-tuned large language model
for long-form text rewriting. We develop new strategies that facilitate the
generation of diverse instructions and preference data with minimal human
intervention. We conduct empirical experiments and demonstrate that our model
outperforms the current state-of-the-art LLMs in text rewriting. Specifically,
it excels in preserving the essential content and meaning of the source text,
minimizing the generation of ''hallucinated'' content, while showcasing the
ability to generate rewrites with diverse wording and structures.


---

## How Good are Commercial Large Language Models on African Languages?

**Published Date:** 2023-05-11T02:29:53Z

**Link:** http://arxiv.org/pdf/2305.06530v1

**Abstract:**

  Recent advancements in Natural Language Processing (NLP) has led to the
proliferation of large pretrained language models. These models have been shown
to yield good performance, using in-context learning, even on unseen tasks and
languages. They have also been exposed as commercial APIs as a form of
language-model-as-a-service, with great adoption. However, their performance on
African languages is largely unknown. We present a preliminary analysis of
commercial large language models on two tasks (machine translation and text
classification) across eight African languages, spanning different language
families and geographical areas. Our results suggest that commercial language
models produce below-par performance on African languages. We also find that
they perform better on text classification than machine translation. In
general, our findings present a call-to-action to ensure African languages are
well represented in commercial large language models, given their growing
popularity.


---

## Images in Language Space: Exploring the Suitability of Large Language
  Models for Vision & Language Tasks

**Published Date:** 2023-05-23T07:50:36Z

**Link:** http://arxiv.org/pdf/2305.13782v1

**Abstract:**

  Large language models have demonstrated robust performance on various
language tasks using zero-shot or few-shot learning paradigms. While being
actively researched, multimodal models that can additionally handle images as
input have yet to catch up in size and generality with language-only models. In
this work, we ask whether language-only models can be utilised for tasks that
require visual input -- but also, as we argue, often require a strong reasoning
component. Similar to some recent related work, we make visual information
accessible to the language model using separate verbalisation models.
Specifically, we investigate the performance of open-source, open-access
language models against GPT-3 on five vision-language tasks when given
textually-encoded visual information. Our results suggest that language models
are effective for solving vision-language tasks even with limited samples. This
approach also enhances the interpretability of a model's output by providing a
means of tracing the output back through the verbalised image content.


---

## Autocorrelations Decay in Texts and Applicability Limits of Language
  Models

**Published Date:** 2023-05-11T07:23:01Z

**Link:** http://arxiv.org/pdf/2305.06615v1

**Abstract:**

  We show that the laws of autocorrelations decay in texts are closely related
to applicability limits of language models. Using distributional semantics we
empirically demonstrate that autocorrelations of words in texts decay according
to a power law. We show that distributional semantics provides coherent
autocorrelations decay exponents for texts translated to multiple languages.
The autocorrelations decay in generated texts is quantitatively and often
qualitatively different from the literary texts. We conclude that language
models exhibiting Markov behavior, including large autoregressive language
models, may have limitations when applied to long texts, whether analysis or
generation.


---

## Exploring Large Language Models for Classical Philology

**Published Date:** 2023-05-23T05:21:02Z

**Link:** http://arxiv.org/pdf/2305.13698v1

**Abstract:**

  Recent advances in NLP have led to the creation of powerful language models
for many languages including Ancient Greek and Latin. While prior work on
Classical languages unanimously uses BERT, in this work we create four language
models for Ancient Greek that vary along two dimensions to study their
versatility for tasks of interest for Classical languages: we explore (i)
encoder-only and encoder-decoder architectures using RoBERTa and T5 as strong
model types, and create for each of them (ii) a monolingual Ancient Greek and a
multilingual instance that includes Latin and English. We evaluate all models
on morphological and syntactic tasks, including lemmatization, which
demonstrates the added value of T5's decoding abilities. We further define two
probing tasks to investigate the knowledge acquired by models pre-trained on
Classical texts. Our experiments provide the first benchmarking analysis of
existing models of Ancient Greek. Results show that our models provide
significant improvements over the SoTA. The systematic analysis of model types
can inform future research in designing language models for Classical
languages, including the development of novel generative tasks. We make all our
models available as community resources, along with a large curated
pre-training corpus for Ancient Greek, to support the creation of a larger,
comparable model zoo for Classical Philology. Our models and resources are
available at https://github.com/Heidelberg-NLP/ancient-language-models.


---

## Chain of Knowledge: A Framework for Grounding Large Language Models with
  Structured Knowledge Bases

**Published Date:** 2023-05-22T17:34:23Z

**Link:** http://arxiv.org/pdf/2305.13269v1

**Abstract:**

  We introduce Chain of Knowledge (CoK), a framework that augments large
language models with structured knowledge bases to improve factual correctness
and reduce hallucination. Compared to previous works which only retrieve
unstructured texts, CoK leverages structured knowledge bases which support
complex queries and offer more direct factual statements. To assist large
language models to effectively query knowledge bases, we propose a query
generator model with contrastive instruction-tuning. As the query generator is
separate from the frozen large language model, our framework is modular and
thus easily adapted to various knowledge sources and models. Experiments show
that our framework significantly enhances the factual correctness of large
language models on knowledge-intensive tasks.


---

## Evaluating the Performance of Large Language Models on GAOKAO Benchmark

**Published Date:** 2023-05-21T14:39:28Z

**Link:** http://arxiv.org/pdf/2305.12474v2

**Abstract:**

  Large language models have demonstrated remarkable performance across various
natural language processing tasks; however, their efficacy in more challenging
and domain-specific tasks remains less explored. This paper introduces the
GAOKAO-Benchmark (GAOKAO-Bench), an intuitive benchmark that employs questions
from the Chinese Gaokao examination as test samples for evaluating large
language models.In order to align the evaluation results with humans as much as
possible, we designed a method based on zero-shot prompts to analyze the
accuracy and scoring rate of the model by dividing the questions into
subjective and objective types. We evaluated the ChatGPT model on
GAOKAO-Benchmark performance.Our findings reveal that the ChatGPT model excels
in tackling objective questions, while also shedding light on its shortcomings
and areas for improvement. To further scrutinize the model's responses, we
incorporate human evaluations.In conclusion, this research contributes a robust
evaluation benchmark for future large-scale language models and offers valuable
insights into the limitations of such models.


---

## Domain Private Transformers

**Published Date:** 2023-05-23T16:27:12Z

**Link:** http://arxiv.org/pdf/2305.14208v1

**Abstract:**

  Large, general purpose language models have demonstrated impressive
performance across many different conversational domains. While multi-domain
language models achieve low overall perplexity, their outputs are not
guaranteed to stay within the domain of a given input prompt. This paper
proposes domain privacy as a novel way to quantify how likely a conditional
language model will leak across domains. We also develop policy functions based
on token-level domain classification, and propose an efficient fine-tuning
method to improve the trained model's domain privacy. Experiments on membership
inference attacks show that our proposed method has comparable resiliency to
methods adapted from recent literature on differentially private language
models.


---

## Drafting Event Schemas using Language Models

**Published Date:** 2023-05-24T07:57:04Z

**Link:** http://arxiv.org/pdf/2305.14847v1

**Abstract:**

  Past work has studied event prediction and event language modeling, sometimes
mediated through structured representations of knowledge in the form of event
schemas. Such schemas can lead to explainable predictions and forecasting of
unseen events given incomplete information. In this work, we look at the
process of creating such schemas to describe complex events. We use large
language models (LLMs) to draft schemas directly in natural language, which can
be further refined by human curators as necessary. Our focus is on whether we
can achieve sufficient diversity and recall of key events and whether we can
produce the schemas in a sufficiently descriptive style. We show that large
language models are able to achieve moderate recall against schemas taken from
two different datasets, with even better results when multiple prompts and
multiple samples are combined. Moreover, we show that textual entailment
methods can be used for both matching schemas to instances of events as well as
evaluating overlap between gold and predicted schemas. Our method paves the way
for easier distillation of event knowledge from large language model into
schemas.


---

## Retentive or Forgetful? Diving into the Knowledge Memorizing Mechanism
  of Language Models

**Published Date:** 2023-05-16T03:50:38Z

**Link:** http://arxiv.org/pdf/2305.09144v1

**Abstract:**

  Memory is one of the most essential cognitive functions serving as a
repository of world knowledge and episodes of activities. In recent years,
large-scale pre-trained language models have shown remarkable memorizing
ability. On the contrary, vanilla neural networks without pre-training have
been long observed suffering from the catastrophic forgetting problem. To
investigate such a retentive-forgetful contradiction and understand the memory
mechanism of language models, we conduct thorough experiments by controlling
the target knowledge types, the learning strategies and the learning schedules.
We find that: 1) Vanilla language models are forgetful; 2) Pre-training leads
to retentive language models; 3) Knowledge relevance and diversification
significantly influence the memory formation. These conclusions are useful for
understanding the abilities of pre-trained language models and shed light on
designing and evaluating new learning and inference algorithms of language
models.


---

## Sensitivity and Robustness of Large Language Models to Prompt Template
  in Japanese Text Classification Tasks

**Published Date:** 2023-05-15T15:19:08Z

**Link:** http://arxiv.org/pdf/2305.08714v2

**Abstract:**

  Prompt engineering relevance research has seen a notable surge in recent
years, primarily driven by advancements in pre-trained language models and
large language models. However, a critical issue has been identified within
this domain: the inadequate of sensitivity and robustness of these models
towards Prompt Templates, particularly in lesser-studied languages such as
Japanese. This paper explores this issue through a comprehensive evaluation of
several representative Large Language Models (LLMs) and a widely-utilized
pre-trained model(PLM). These models are scrutinized using a benchmark dataset
in Japanese, with the aim to assess and analyze the performance of the current
multilingual models in this context. Our experimental results reveal startling
discrepancies. A simple modification in the sentence structure of the Prompt
Template led to a drastic drop in the accuracy of GPT-4 from 49.21 to 25.44.
This observation underscores the fact that even the highly performance GPT-4
model encounters significant stability issues when dealing with diverse
Japanese prompt templates, rendering the consistency of the model's output
results questionable. In light of these findings, we conclude by proposing
potential research trajectories to further enhance the development and
performance of Large Language Models in their current stage.


---

## An Efficient Multilingual Language Model Compression through Vocabulary
  Trimming

**Published Date:** 2023-05-24T11:00:33Z

**Link:** http://arxiv.org/pdf/2305.15020v1

**Abstract:**

  Multilingual language model (LM) have become a powerful tool in NLP
especially for non-English languages. Nevertheless, model parameters of
multilingual LMs remain large due to the larger embedding matrix of the
vocabulary covering tokens in different languages. On the contrary, monolingual
LMs can be trained in a target language with the language-specific vocabulary
only, but this requires a large budget and availability of reliable corpora to
achieve a high-quality LM from scratch. In this paper, we propose
vocabulary-trimming (VT), a method to reduce a multilingual LM vocabulary to a
target language by deleting irrelevant tokens from its vocabulary. In theory,
VT can compress any existing multilingual LM to build monolingual LMs in any
language covered by the multilingual LM. In our experiments, we show that VT
can retain the original performance of the multilingual LM, while being smaller
in size (in general around 50% of the original vocabulary size is enough) than
the original multilingual LM. The evaluation is performed over four NLP tasks
(two generative and two classification tasks) among four widely used
multilingual LMs in seven languages. Finally, we show that this methodology can
keep the best of both monolingual and multilingual worlds by keeping a small
size as monolingual models without the need for specifically retraining them,
and even limiting potentially harmful social biases.


---

## Towards Explainable and Language-Agnostic LLMs: Symbolic Reverse
  Engineering of Language at Scale

**Published Date:** 2023-05-30T15:15:40Z

**Link:** http://arxiv.org/pdf/2306.00017v4

**Abstract:**

  Large language models (LLMs) have achieved a milestone that undenia-bly
changed many held beliefs in artificial intelligence (AI). However, there
remains many limitations of these LLMs when it comes to true language
understanding, limitations that are a byproduct of the under-lying architecture
of deep neural networks. Moreover, and due to their subsymbolic nature,
whatever knowledge these models acquire about how language works will always be
buried in billions of microfeatures (weights), none of which is meaningful on
its own, making such models hopelessly unexplainable. To address these
limitations, we suggest com-bining the strength of symbolic representations
with what we believe to be the key to the success of LLMs, namely a successful
bottom-up re-verse engineering of language at scale. As such we argue for a
bottom-up reverse engineering of language in a symbolic setting. Hints on what
this project amounts to have been suggested by several authors, and we discuss
in some detail here how this project could be accomplished.


---

## Cream: Visually-Situated Natural Language Understanding with Contrastive
  Reading Model and Frozen Large Language Models

**Published Date:** 2023-05-24T11:59:13Z

**Link:** http://arxiv.org/pdf/2305.15080v1

**Abstract:**

  Advances in Large Language Models (LLMs) have inspired a surge of research
exploring their expansion into the visual domain. While recent models exhibit
promise in generating abstract captions for images and conducting natural
conversations, their performance on text-rich images leaves room for
improvement. In this paper, we propose the Contrastive Reading Model (Cream), a
novel neural architecture designed to enhance the language-image understanding
capability of LLMs by capturing intricate details typically overlooked by
existing methods. Cream integrates vision and auxiliary encoders, complemented
by a contrastive feature alignment technique, resulting in a more effective
understanding of textual information within document images. Our approach,
thus, seeks to bridge the gap between vision and language understanding, paving
the way for more sophisticated Document Intelligence Assistants. Rigorous
evaluations across diverse tasks, such as visual question answering on document
images, demonstrate the efficacy of Cream as a state-of-the-art model in the
field of visual document understanding. We provide our codebase and
newly-generated datasets at https://github.com/naver-ai/cream


---

## ArtGPT-4: Artistic Vision-Language Understanding with Adapter-enhanced
  MiniGPT-4

**Published Date:** 2023-05-12T14:04:30Z

**Link:** http://arxiv.org/pdf/2305.07490v2

**Abstract:**

  In recent years, large language models (LLMs) have made significant progress
in natural language processing (NLP), with models like ChatGPT and GPT-4
achieving impressive capabilities in various linguistic tasks. However,
training models on such a large scale is challenging, and finding datasets that
match the model's scale is often difficult. Fine-tuning and training models
with fewer parameters using novel methods have emerged as promising approaches
to overcome these challenges. One such model is MiniGPT-4, which achieves
comparable vision-language understanding to GPT-4 by leveraging novel
pre-training models and innovative training strategies. However, the model
still faces some challenges in image understanding, particularly in artistic
pictures. A novel multimodal model called ArtGPT-4 has been proposed to address
these limitations. ArtGPT-4 was trained on image-text pairs using a Tesla A100
device in just 2 hours, using only about 200 GB of data. The model can depict
images with an artistic flair and generate visual code, including aesthetically
pleasing HTML/CSS web pages. Furthermore, the article proposes novel benchmarks
for evaluating the performance of vision-language models. In the subsequent
evaluation methods, ArtGPT-4 scored more than 1 point higher than the current
\textbf{state-of-the-art} model and was only 0.25 points lower than artists on
a 6-point scale. Our code and pre-trained model are available at
\url{https://huggingface.co/Tyrannosaurus/ArtGPT-4}.


---

## How Good are Commercial Large Language Models on African Languages?

**first_author:** Jessica Ojo et al.

**Published Date:** 2023-05-11T02:29:53Z

**Link:** http://arxiv.org/pdf/2305.06530v1

**Abstract:**

  Recent advancements in Natural Language Processing (NLP) has led to the
proliferation of large pretrained language models. These models have been shown
to yield good performance, using in-context learning, even on unseen tasks and
languages. They have also been exposed as commercial APIs as a form of
language-model-as-a-service, with great adoption. However, their performance on
African languages is largely unknown. We present a preliminary analysis of
commercial large language models on two tasks (machine translation and text
classification) across eight African languages, spanning different language
families and geographical areas. Our results suggest that commercial language
models produce below-par performance on African languages. We also find that
they perform better on text classification than machine translation. In
general, our findings present a call-to-action to ensure African languages are
well represented in commercial large language models, given their growing
popularity.


---

## Images in Language Space: Exploring the Suitability of Large Language
  Models for Vision & Language Tasks

**first_author:** Sherzod Hakimov et al.

**Published Date:** 2023-05-23T07:50:36Z

**Link:** http://arxiv.org/pdf/2305.13782v1

**Abstract:**

  Large language models have demonstrated robust performance on various
language tasks using zero-shot or few-shot learning paradigms. While being
actively researched, multimodal models that can additionally handle images as
input have yet to catch up in size and generality with language-only models. In
this work, we ask whether language-only models can be utilised for tasks that
require visual input -- but also, as we argue, often require a strong reasoning
component. Similar to some recent related work, we make visual information
accessible to the language model using separate verbalisation models.
Specifically, we investigate the performance of open-source, open-access
language models against GPT-3 on five vision-language tasks when given
textually-encoded visual information. Our results suggest that language models
are effective for solving vision-language tasks even with limited samples. This
approach also enhances the interpretability of a model's output by providing a
means of tracing the output back through the verbalised image content.


---

## Autocorrelations Decay in Texts and Applicability Limits of Language
  Models

**first_author:** Nikolay Mikhaylovskiy et al.

**Published Date:** 2023-05-11T07:23:01Z

**Link:** http://arxiv.org/pdf/2305.06615v1

**Abstract:**

  We show that the laws of autocorrelations decay in texts are closely related
to applicability limits of language models. Using distributional semantics we
empirically demonstrate that autocorrelations of words in texts decay according
to a power law. We show that distributional semantics provides coherent
autocorrelations decay exponents for texts translated to multiple languages.
The autocorrelations decay in generated texts is quantitatively and often
qualitatively different from the literary texts. We conclude that language
models exhibiting Markov behavior, including large autoregressive language
models, may have limitations when applied to long texts, whether analysis or
generation.


---

## Can Large Language Models Infer and Disagree Like Humans?

**first_author:** Noah Lee et al.

**Published Date:** 2023-05-23T07:55:34Z

**Link:** http://arxiv.org/pdf/2305.13788v1

**Abstract:**

  Large Language Models (LLMs) have shown stellar achievements in solving a
broad range of tasks. When generating text, it is common to sample tokens from
these models: whether LLMs closely align with the human disagreement
distribution has not been well-studied, especially within the scope of Natural
Language Inference (NLI). In this paper, we evaluate the performance and
alignment of LLM distribution with humans using two different techniques: Monte
Carlo Reconstruction (MCR) and Log Probability Reconstruction (LPR). As a
result, we show LLMs exhibit limited ability in solving NLI tasks and
simultaneously fail to capture human disagreement distribution, raising
concerns about their natural language understanding (NLU) ability and their
representativeness of human users.


---

## Exploring Large Language Models for Classical Philology

**first_author:** Frederick Riemenschneider et al.

**Published Date:** 2023-05-23T05:21:02Z

**Link:** http://arxiv.org/pdf/2305.13698v1

**Abstract:**

  Recent advances in NLP have led to the creation of powerful language models
for many languages including Ancient Greek and Latin. While prior work on
Classical languages unanimously uses BERT, in this work we create four language
models for Ancient Greek that vary along two dimensions to study their
versatility for tasks of interest for Classical languages: we explore (i)
encoder-only and encoder-decoder architectures using RoBERTa and T5 as strong
model types, and create for each of them (ii) a monolingual Ancient Greek and a
multilingual instance that includes Latin and English. We evaluate all models
on morphological and syntactic tasks, including lemmatization, which
demonstrates the added value of T5's decoding abilities. We further define two
probing tasks to investigate the knowledge acquired by models pre-trained on
Classical texts. Our experiments provide the first benchmarking analysis of
existing models of Ancient Greek. Results show that our models provide
significant improvements over the SoTA. The systematic analysis of model types
can inform future research in designing language models for Classical
languages, including the development of novel generative tasks. We make all our
models available as community resources, along with a large curated
pre-training corpus for Ancient Greek, to support the creation of a larger,
comparable model zoo for Classical Philology. Our models and resources are
available at https://github.com/Heidelberg-NLP/ancient-language-models.


---

## Evaluating the Performance of Large Language Models on GAOKAO Benchmark

**first_author:** Xiaotian Zhang et al.

**Published Date:** 2023-05-21T14:39:28Z

**Link:** http://arxiv.org/pdf/2305.12474v2

**Abstract:**

  Large language models have demonstrated remarkable performance across various
natural language processing tasks; however, their efficacy in more challenging
and domain-specific tasks remains less explored. This paper introduces the
GAOKAO-Benchmark (GAOKAO-Bench), an intuitive benchmark that employs questions
from the Chinese Gaokao examination as test samples for evaluating large
language models.In order to align the evaluation results with humans as much as
possible, we designed a method based on zero-shot prompts to analyze the
accuracy and scoring rate of the model by dividing the questions into
subjective and objective types. We evaluated the ChatGPT model on
GAOKAO-Benchmark performance.Our findings reveal that the ChatGPT model excels
in tackling objective questions, while also shedding light on its shortcomings
and areas for improvement. To further scrutinize the model's responses, we
incorporate human evaluations.In conclusion, this research contributes a robust
evaluation benchmark for future large-scale language models and offers valuable
insights into the limitations of such models.


---

## Domain Private Transformers

**first_author:** Anmol Kabra et al.

**Published Date:** 2023-05-23T16:27:12Z

**Link:** http://arxiv.org/pdf/2305.14208v1

**Abstract:**

  Large, general purpose language models have demonstrated impressive
performance across many different conversational domains. While multi-domain
language models achieve low overall perplexity, their outputs are not
guaranteed to stay within the domain of a given input prompt. This paper
proposes domain privacy as a novel way to quantify how likely a conditional
language model will leak across domains. We also develop policy functions based
on token-level domain classification, and propose an efficient fine-tuning
method to improve the trained model's domain privacy. Experiments on membership
inference attacks show that our proposed method has comparable resiliency to
methods adapted from recent literature on differentially private language
models.


---

## Sensitivity and Robustness of Large Language Models to Prompt Template
  in Japanese Text Classification Tasks

**first_author:** Chengguang Gan et al.

**Published Date:** 2023-05-15T15:19:08Z

**Link:** http://arxiv.org/pdf/2305.08714v2

**Abstract:**

  Prompt engineering relevance research has seen a notable surge in recent
years, primarily driven by advancements in pre-trained language models and
large language models. However, a critical issue has been identified within
this domain: the inadequate of sensitivity and robustness of these models
towards Prompt Templates, particularly in lesser-studied languages such as
Japanese. This paper explores this issue through a comprehensive evaluation of
several representative Large Language Models (LLMs) and a widely-utilized
pre-trained model(PLM). These models are scrutinized using a benchmark dataset
in Japanese, with the aim to assess and analyze the performance of the current
multilingual models in this context. Our experimental results reveal startling
discrepancies. A simple modification in the sentence structure of the Prompt
Template led to a drastic drop in the accuracy of GPT-4 from 49.21 to 25.44.
This observation underscores the fact that even the highly performance GPT-4
model encounters significant stability issues when dealing with diverse
Japanese prompt templates, rendering the consistency of the model's output
results questionable. In light of these findings, we conclude by proposing
potential research trajectories to further enhance the development and
performance of Large Language Models in their current stage.


---

