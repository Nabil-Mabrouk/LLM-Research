## Using large language models for (de-)formalization and natural
  argumentation exercises for beginner's students

**Published Date:** 2023-04-12T23:05:02Z

**Link:** http://arxiv.org/pdf/2304.06186v1

**Abstract:**

  We describe two systems that use text-davinci-003, a large language model,
for the automatized correction of (i) exercises in translating back and forth
between natural language and the languages of propositional logic and
first-order predicate logic and (ii) exercises in writing simple arguments in
natural language in non-mathematical scenarios.


---

## Unsupervised Improvement of Factual Knowledge in Language Models

**Published Date:** 2023-04-04T07:37:06Z

**Link:** http://arxiv.org/pdf/2304.01597v1

**Abstract:**

  Masked language modeling (MLM) plays a key role in pretraining large language
models. But the MLM objective is often dominated by high-frequency words that
are sub-optimal for learning factual knowledge. In this work, we propose an
approach for influencing MLM pretraining in a way that can improve language
model performance on a variety of knowledge-intensive tasks. We force the
language model to prioritize informative words in a fully unsupervised way.
Experiments demonstrate that the proposed approach can significantly improve
the performance of pretrained language models on tasks such as factual recall,
question answering, sentiment analysis, and natural language inference in a
closed-book setting.


---

## A Simple and Effective Method of Cross-Lingual Plagiarism Detection

**Published Date:** 2023-04-03T20:27:10Z

**Link:** http://arxiv.org/pdf/2304.01352v2

**Abstract:**

  We present a simple cross-lingual plagiarism detection method applicable to a
large number of languages. The presented approach leverages open multilingual
thesauri for candidate retrieval task and pre-trained multilingual BERT-based
language models for detailed analysis. The method does not rely on machine
translation and word sense disambiguation when in use, and therefore is
suitable for a large number of languages, including under-resourced languages.
The effectiveness of the proposed approach is demonstrated for several existing
and new benchmarks, achieving state-of-the-art results for French, Russian, and
Armenian languages.


---

## UniMax: Fairer and more Effective Language Sampling for Large-Scale
  Multilingual Pretraining

**Published Date:** 2023-04-18T17:45:50Z

**Link:** http://arxiv.org/pdf/2304.09151v1

**Abstract:**

  Pretrained multilingual large language models have typically used heuristic
temperature-based sampling to balance between different languages. However
previous work has not systematically evaluated the efficacy of different
pretraining language distributions across model scales. In this paper, we
propose a new sampling method, UniMax, that delivers more uniform coverage of
head languages while mitigating overfitting on tail languages by explicitly
capping the number of repeats over each language's corpus. We perform an
extensive series of ablations testing a range of sampling strategies on a suite
of multilingual benchmarks, while varying model scale. We find that UniMax
outperforms standard temperature-based sampling, and the benefits persist as
scale increases. As part of our contribution, we release: (i) an improved and
refreshed mC4 multilingual corpus consisting of 29 trillion characters across
107 languages, and (ii) a suite of pretrained umT5 model checkpoints trained
with UniMax sampling.


---

## Large Language Models for Business Process Management: Opportunities and
  Challenges

**Published Date:** 2023-04-09T20:32:09Z

**Link:** http://arxiv.org/pdf/2304.04309v1

**Abstract:**

  Large language models are deep learning models with a large number of
parameters. The models made noticeable progress on a large number of tasks, and
as a consequence allowing them to serve as valuable and versatile tools for a
diverse range of applications. Their capabilities also offer opportunities for
business process management, however, these opportunities have not yet been
systematically investigated. In this paper, we address this research problem by
foregrounding various management tasks of the BPM lifecycle. We investigate six
research directions highlighting problems that need to be addressed when using
large language models, including usage guidelines for practitioners.


---

## Unstructured and structured data: Can we have the best of both worlds
  with large language models?

**Published Date:** 2023-04-25T17:30:05Z

**Link:** http://arxiv.org/pdf/2304.13010v2

**Abstract:**

  This paper presents an opinion on the potential of using large language
models to query on both unstructured and structured data. It also outlines some
research challenges related to the topic of building question-answering systems
for both types of data.


---

## Romanization-based Large-scale Adaptation of Multilingual Language
  Models

**Published Date:** 2023-04-18T09:58:34Z

**Link:** http://arxiv.org/pdf/2304.08865v1

**Abstract:**

  Large multilingual pretrained language models (mPLMs) have become the de
facto state of the art for cross-lingual transfer in NLP. However, their
large-scale deployment to many languages, besides pretraining data scarcity, is
also hindered by the increase in vocabulary size and limitations in their
parameter budget. In order to boost the capacity of mPLMs to deal with
low-resource and unseen languages, we explore the potential of leveraging
transliteration on a massive scale. In particular, we explore the UROMAN
transliteration tool, which provides mappings from UTF-8 to Latin characters
for all the writing systems, enabling inexpensive romanization for virtually
any language. We first focus on establishing how UROMAN compares against other
language-specific and manually curated transliterators for adapting
multilingual PLMs. We then study and compare a plethora of data- and
parameter-efficient strategies for adapting the mPLMs to romanized and
non-romanized corpora of 14 diverse low-resource languages. Our results reveal
that UROMAN-based transliteration can offer strong performance for many
languages, with particular gains achieved in the most challenging setups: on
languages with unseen scripts and with limited training data without any
vocabulary augmentation. Further analyses reveal that an improved tokenizer
based on romanized data can even outperform non-transliteration-based methods
in the majority of languages.


---

## Using large language models for (de-)formalization and natural
  argumentation exercises for beginner's students

**Published Date:** 2023-04-12T23:05:02Z

**Link:** http://arxiv.org/pdf/2304.06186v1

**Abstract:**

  We describe two systems that use text-davinci-003, a large language model,
for the automatized correction of (i) exercises in translating back and forth
between natural language and the languages of propositional logic and
first-order predicate logic and (ii) exercises in writing simple arguments in
natural language in non-mathematical scenarios.


---

## Large Language Models for Business Process Management: Opportunities and
  Challenges

**Published Date:** 2023-04-09T20:32:09Z

**Link:** http://arxiv.org/pdf/2304.04309v1

**Abstract:**

  Large language models are deep learning models with a large number of
parameters. The models made noticeable progress on a large number of tasks, and
as a consequence allowing them to serve as valuable and versatile tools for a
diverse range of applications. Their capabilities also offer opportunities for
business process management, however, these opportunities have not yet been
systematically investigated. In this paper, we address this research problem by
foregrounding various management tasks of the BPM lifecycle. We investigate six
research directions highlighting problems that need to be addressed when using
large language models, including usage guidelines for practitioners.


---

## Should ChatGPT be Biased? Challenges and Risks of Bias in Large Language
  Models

**Published Date:** 2023-04-07T17:14:00Z

**Link:** http://arxiv.org/pdf/2304.03738v2

**Abstract:**

  As the capabilities of generative language models continue to advance, the
implications of biases ingrained within these models have garnered increasing
attention from researchers, practitioners, and the broader public. This article
investigates the challenges and risks associated with biases in large-scale
language models like ChatGPT. We discuss the origins of biases, stemming from,
among others, the nature of training data, model specifications, algorithmic
constraints, product design, and policy decisions. We explore the ethical
concerns arising from the unintended consequences of biased model outputs. We
further analyze the potential opportunities to mitigate biases, the
inevitability of some biases, and the implications of deploying these models in
various applications, such as virtual assistants, content generation, and
chatbots. Finally, we review the current approaches to identify, quantify, and
mitigate biases in language models, emphasizing the need for a
multi-disciplinary, collaborative effort to develop more equitable,
transparent, and responsible AI systems. This article aims to stimulate a
thoughtful dialogue within the artificial intelligence community, encouraging
researchers and developers to reflect on the role of biases in generative
language models and the ongoing pursuit of ethical AI.


---

## POUF: Prompt-oriented unsupervised fine-tuning for large pre-trained
  models

**Published Date:** 2023-04-29T22:05:22Z

**Link:** http://arxiv.org/pdf/2305.00350v1

**Abstract:**

  Through prompting, large-scale pre-trained models have become more expressive
and powerful, gaining significant attention in recent years. Though these big
models have zero-shot capabilities, in general, labeled data are still required
to adapt them to downstream tasks. To overcome this critical limitation, we
propose an unsupervised fine-tuning framework to directly fine-tune the model
or prompt on the unlabeled target data. We demonstrate how to apply our method
to both language-augmented vision and masked-language models by aligning the
discrete distributions extracted from the prompts and target data. To verify
our approach's applicability, we conduct extensive experiments on image
classification, sentiment analysis, and natural language inference tasks.
Across 13 image-related tasks and 15 language-related ones, the proposed
approach achieves consistent improvements over the baselines.


---

## Using large language models for (de-)formalization and natural
  argumentation exercises for beginner's students

**first_author:** Merlin Carl et al.

**Published Date:** 2023-04-12T23:05:02Z

**Link:** http://arxiv.org/pdf/2304.06186v1

**Abstract:**

  We describe two systems that use text-davinci-003, a large language model,
for the automatized correction of (i) exercises in translating back and forth
between natural language and the languages of propositional logic and
first-order predicate logic and (ii) exercises in writing simple arguments in
natural language in non-mathematical scenarios.


---

## Large Language Models for Business Process Management: Opportunities and
  Challenges

**first_author:** Maxim Vidgof et al.

**Published Date:** 2023-04-09T20:32:09Z

**Link:** http://arxiv.org/pdf/2304.04309v1

**Abstract:**

  Large language models are deep learning models with a large number of
parameters. The models made noticeable progress on a large number of tasks, and
as a consequence allowing them to serve as valuable and versatile tools for a
diverse range of applications. Their capabilities also offer opportunities for
business process management, however, these opportunities have not yet been
systematically investigated. In this paper, we address this research problem by
foregrounding various management tasks of the BPM lifecycle. We investigate six
research directions highlighting problems that need to be addressed when using
large language models, including usage guidelines for practitioners.


---

## Should ChatGPT be Biased? Challenges and Risks of Bias in Large Language
  Models

**first_author:** Emilio Ferrara et al.

**Published Date:** 2023-04-07T17:14:00Z

**Link:** http://arxiv.org/pdf/2304.03738v2

**Abstract:**

  As the capabilities of generative language models continue to advance, the
implications of biases ingrained within these models have garnered increasing
attention from researchers, practitioners, and the broader public. This article
investigates the challenges and risks associated with biases in large-scale
language models like ChatGPT. We discuss the origins of biases, stemming from,
among others, the nature of training data, model specifications, algorithmic
constraints, product design, and policy decisions. We explore the ethical
concerns arising from the unintended consequences of biased model outputs. We
further analyze the potential opportunities to mitigate biases, the
inevitability of some biases, and the implications of deploying these models in
various applications, such as virtual assistants, content generation, and
chatbots. Finally, we review the current approaches to identify, quantify, and
mitigate biases in language models, emphasizing the need for a
multi-disciplinary, collaborative effort to develop more equitable,
transparent, and responsible AI systems. This article aims to stimulate a
thoughtful dialogue within the artificial intelligence community, encouraging
researchers and developers to reflect on the role of biases in generative
language models and the ongoing pursuit of ethical AI.


---

