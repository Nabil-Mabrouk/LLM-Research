## DesCo: Learning Object Recognition with Rich Language Descriptions

**Published Date:** 2023-06-24T21:05:02Z

**Link:** http://arxiv.org/pdf/2306.14060v1

**Abstract:**

  Recent development in vision-language approaches has instigated a paradigm
shift in learning visual recognition models from language supervision. These
approaches align objects with language queries (e.g. "a photo of a cat") and
improve the models' adaptability to identify novel objects and domains.
Recently, several studies have attempted to query these models with complex
language expressions that include specifications of fine-grained semantic
details, such as attributes, shapes, textures, and relations. However, simply
incorporating language descriptions as queries does not guarantee accurate
interpretation by the models. In fact, our experiments show that GLIP, the
state-of-the-art vision-language model for object detection, often disregards
contextual information in the language descriptions and instead relies heavily
on detecting objects solely by their names. To tackle the challenges, we
propose a new description-conditioned (DesCo) paradigm of learning object
recognition models with rich language descriptions consisting of two major
innovations: 1) we employ a large language model as a commonsense knowledge
engine to generate rich language descriptions of objects based on object names
and the raw image-text caption; 2) we design context-sensitive queries to
improve the model's ability in deciphering intricate nuances embedded within
descriptions and enforce the model to focus on context rather than object names
alone. On two novel object detection benchmarks, LVIS and OminiLabel, under the
zero-shot detection setting, our approach achieves 34.8 APr minival (+9.1) and
29.3 AP (+3.6), respectively, surpassing the prior state-of-the-art models,
GLIP and FIBER, by a large margin.


---

## Knowledge of cultural moral norms in large language models

**Published Date:** 2023-06-02T18:23:35Z

**Link:** http://arxiv.org/pdf/2306.01857v1

**Abstract:**

  Moral norms vary across cultures. A recent line of work suggests that English
large language models contain human-like moral biases, but these studies
typically do not examine moral variation in a diverse cultural setting. We
investigate the extent to which monolingual English language models contain
knowledge about moral norms in different countries. We consider two levels of
analysis: 1) whether language models capture fine-grained moral variation
across countries over a variety of topics such as ``homosexuality'' and
``divorce''; 2) whether language models capture cultural diversity and shared
tendencies in which topics people around the globe tend to diverge or agree on
in their moral judgment. We perform our analyses with two public datasets from
the World Values Survey (across 55 countries) and PEW global surveys (across 40
countries) on morality. We find that pre-trained English language models
predict empirical moral norms across countries worse than the English moral
norms reported previously. However, fine-tuning language models on the survey
data improves inference across countries at the expense of a less accurate
estimate of the English moral norms. We discuss the relevance and challenges of
incorporating cultural knowledge into the automated inference of moral norms.


---

## Knowledge of cultural moral norms in large language models

**Published Date:** 2023-06-02T18:23:35Z

**Link:** http://arxiv.org/pdf/2306.01857v1

**Abstract:**

  Moral norms vary across cultures. A recent line of work suggests that English
large language models contain human-like moral biases, but these studies
typically do not examine moral variation in a diverse cultural setting. We
investigate the extent to which monolingual English language models contain
knowledge about moral norms in different countries. We consider two levels of
analysis: 1) whether language models capture fine-grained moral variation
across countries over a variety of topics such as ``homosexuality'' and
``divorce''; 2) whether language models capture cultural diversity and shared
tendencies in which topics people around the globe tend to diverge or agree on
in their moral judgment. We perform our analyses with two public datasets from
the World Values Survey (across 55 countries) and PEW global surveys (across 40
countries) on morality. We find that pre-trained English language models
predict empirical moral norms across countries worse than the English moral
norms reported previously. However, fine-tuning language models on the survey
data improves inference across countries at the expense of a less accurate
estimate of the English moral norms. We discuss the relevance and challenges of
incorporating cultural knowledge into the automated inference of moral norms.


---

## Knowledge of cultural moral norms in large language models

**first_author:** Aida Ramezani et al.

**Published Date:** 2023-06-02T18:23:35Z

**Link:** http://arxiv.org/pdf/2306.01857v1

**Abstract:**

  Moral norms vary across cultures. A recent line of work suggests that English
large language models contain human-like moral biases, but these studies
typically do not examine moral variation in a diverse cultural setting. We
investigate the extent to which monolingual English language models contain
knowledge about moral norms in different countries. We consider two levels of
analysis: 1) whether language models capture fine-grained moral variation
across countries over a variety of topics such as ``homosexuality'' and
``divorce''; 2) whether language models capture cultural diversity and shared
tendencies in which topics people around the globe tend to diverge or agree on
in their moral judgment. We perform our analyses with two public datasets from
the World Values Survey (across 55 countries) and PEW global surveys (across 40
countries) on morality. We find that pre-trained English language models
predict empirical moral norms across countries worse than the English moral
norms reported previously. However, fine-tuning language models on the survey
data improves inference across countries at the expense of a less accurate
estimate of the English moral norms. We discuss the relevance and challenges of
incorporating cultural knowledge into the automated inference of moral norms.


---

