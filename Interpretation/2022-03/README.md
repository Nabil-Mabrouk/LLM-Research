## Leashing the Inner Demons: Self-Detoxification for Language Models

**Published Date:** 2022-03-06T23:55:12Z

**Link:** http://arxiv.org/pdf/2203.03072v1

**Abstract:**

  Language models (LMs) can reproduce (or amplify) toxic language seen during
training, which poses a risk to their practical application. In this paper, we
conduct extensive experiments to study this phenomenon. We analyze the impact
of prompts, decoding strategies and training corpora on the output toxicity.
Based on our findings, we propose a simple yet effective method for language
models to "detoxify" themselves without an additional large corpus or external
discriminator. Compared to a supervised baseline, our proposed method shows
better toxicity reduction with good generation quality in the generated content
under multiple settings. Warning: some examples shown in the paper may contain
uncensored offensive content.


---

